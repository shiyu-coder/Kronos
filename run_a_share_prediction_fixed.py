#!/usr/bin/env python3
"""
Aè‚¡è‚¡ç¥¨é¢„æµ‹è¿è¡Œè„šæœ¬ - ä¿®å¤ç‰ˆæœ¬
ä½¿ç”¨Kronosæ¨¡å‹å¯¹Aè‚¡è‚¡ç¥¨è¿›è¡Œé¢„æµ‹
ä¿®å¤äº†æ¨¡å‹åŠ è½½é…ç½®é—®é¢˜
"""

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
import sys
import os
from pathlib import Path
import torch
import warnings
warnings.filterwarnings("ignore")

# ä¿®å¤matplotlibä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
def setup_chinese_font():
    """è®¾ç½®matplotlibä¸­æ–‡å­—ä½“ - å®ç”¨ç‰ˆæœ¬"""
    try:
        import matplotlib.font_manager as fm
        
        # æŸ¥æ‰¾ç³»ç»Ÿä¸­å¯ç”¨çš„ä¸­æ–‡å­—ä½“
        chinese_fonts = [
            'SimHei',           # é»‘ä½“ (Windows)
            'Microsoft YaHei',  # å¾®è½¯é›…é»‘ (Windows)
            'PingFang SC',      # Mac
            'Hiragino Sans GB', # Mac
            'WenQuanYi Micro Hei', # Linux
            'Noto Sans CJK SC', # Google Noto
            'Source Han Sans SC' # æ€æºé»‘ä½“
        ]
        
        # è·å–ç³»ç»Ÿä¸­æ‰€æœ‰å¯ç”¨å­—ä½“
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
        found_font = None
        for font in chinese_fonts:
            if font in available_fonts:
                found_font = font
                break
        
        if found_font:
            # è®¾ç½®æ‰¾åˆ°çš„ä¸­æ–‡å­—ä½“
            matplotlib.rcParams['font.sans-serif'] = [found_font] + matplotlib.rcParams['font.sans-serif']
            matplotlib.rcParams['font.family'] = 'sans-serif'
            print(f"   âœ… æˆåŠŸè®¾ç½®ä¸­æ–‡å­—ä½“: {found_font}")
            return True
        else:
            # æ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨è‹±æ–‡æ›¿ä»£æ–¹æ¡ˆ
            print("   âš ï¸  ç³»ç»Ÿä¸­æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“")
            print("   ğŸ“ å°†ä½¿ç”¨è‹±æ–‡æ ‡ç­¾ä»¥é¿å…ä¹±ç ")
            matplotlib.rcParams['font.family'] = 'DejaVu Sans'
            matplotlib.rcParams['axes.unicode_minus'] = False
            return False
            
    except Exception as e:
        print(f"   âš ï¸  å­—ä½“è®¾ç½®å¤±è´¥: {e}")
        # ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        matplotlib.rcParams['font.family'] = 'DejaVu Sans'
        matplotlib.rcParams['axes.unicode_minus'] = False
        return False

# åˆå§‹åŒ–ä¸­æ–‡å­—ä½“å¹¶è·å–æ˜¯å¦æ”¯æŒä¸­æ–‡
chinese_supported = setup_chinese_font()

# æ·»åŠ modelæ¨¡å—åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / "model"))

try:
    from model import Kronos, KronosTokenizer, KronosPredictor
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œå°è¯•ç›´æ¥ä»kronosæ¨¡å—å¯¼å…¥
    from kronos import KronosTokenizer, Kronos, KronosPredictor

def plot_prediction(kline_df, pred_df, use_chinese=True):
    """ç»˜åˆ¶é¢„æµ‹ç»“æœå¯¹æ¯”å›¾"""
    pred_df.index = kline_df.index[-pred_df.shape[0]:]
    
    # æ ¹æ®ä¸­æ–‡æ”¯æŒæƒ…å†µé€‰æ‹©æ ‡ç­¾
    if use_chinese and chinese_supported:
        # ä¸­æ–‡æ ‡ç­¾
        labels = {
            'actual_price': 'çœŸå®ä»·æ ¼',
            'pred_price': 'é¢„æµ‹ä»·æ ¼',
            'actual_volume': 'çœŸå®æˆäº¤é‡',
            'pred_volume': 'é¢„æµ‹æˆäº¤é‡',
            'price_ylabel': 'æ”¶ç›˜ä»·',
            'volume_ylabel': 'æˆäº¤é‡',
            'time_xlabel': 'æ—¶é—´',
            'title': 'Aè‚¡è‚¡ç¥¨ä»·æ ¼é¢„æµ‹å¯¹æ¯” (ä¿®å¤ç‰ˆ)'
        }
    else:
        # è‹±æ–‡æ ‡ç­¾ï¼ˆé¿å…ä¹±ç ï¼‰
        labels = {
            'actual_price': 'Actual Price',
            'pred_price': 'Predicted Price',
            'actual_volume': 'Actual Volume',
            'pred_volume': 'Predicted Volume',
            'price_ylabel': 'Close Price',
            'volume_ylabel': 'Volume',
            'time_xlabel': 'Time',
            'title': 'A-Share Stock Prediction Comparison (Fixed)'
        }
    
    sr_close = kline_df['close']
    sr_pred_close = pred_df['close']
    sr_close.name = labels['actual_price']
    sr_pred_close.name = labels['pred_price']

    sr_volume = kline_df['volume']
    sr_pred_volume = pred_df['volume']
    sr_volume.name = labels['actual_volume']
    sr_pred_volume.name = labels['pred_volume']

    close_df = pd.concat([sr_close, sr_pred_close], axis=1)
    volume_df = pd.concat([sr_volume, sr_pred_volume], axis=1)

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)

    ax1.plot(close_df[labels['actual_price']], label=labels['actual_price'], color='blue', linewidth=1.5)
    ax1.plot(close_df[labels['pred_price']], label=labels['pred_price'], color='red', linewidth=1.5)
    ax1.set_ylabel(labels['price_ylabel'], fontsize=14)
    ax1.legend(loc='lower left', fontsize=12)
    ax1.grid(True)
    ax1.set_title(labels['title'], fontsize=16)

    ax2.plot(volume_df[labels['actual_volume']], label=labels['actual_volume'], color='blue', linewidth=1.5)
    ax2.plot(volume_df[labels['pred_volume']], label=labels['pred_volume'], color='red', linewidth=1.5)
    ax2.set_ylabel(labels['volume_ylabel'], fontsize=14)
    ax2.set_xlabel(labels['time_xlabel'], fontsize=14)
    ax2.legend(loc='upper left', fontsize=12)
    ax2.grid(True)

    plt.tight_layout()
    plt.savefig('a_share_prediction_result_fixed.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # è¾“å‡ºå­—ä½“ä½¿ç”¨ä¿¡æ¯
    if use_chinese and chinese_supported:
        print("   ğŸ“ å›¾è¡¨ä½¿ç”¨ä¸­æ–‡æ ‡ç­¾")
    else:
        print("   ğŸ“ å›¾è¡¨ä½¿ç”¨è‹±æ–‡æ ‡ç­¾ä»¥é¿å…ä¹±ç ")

def create_tokenizer_with_config():
    """åˆ›å»ºå…·æœ‰é»˜è®¤é…ç½®çš„tokenizer"""
    # æ ¹æ®Kronos-Tokenizer-baseçš„å…¸å‹é…ç½®
    tokenizer_config = {
        'd_in': 6,  # OHLCV + amount (6 features)
        'd_model': 256,
        'n_heads': 8,
        'ff_dim': 1024,
        'n_enc_layers': 4,
        'n_dec_layers': 4,
        'ffn_dropout_p': 0.1,
        'attn_dropout_p': 0.1,
        'resid_dropout_p': 0.1,
        's1_bits': 8,
        's2_bits': 8,
        'beta': 0.25,
        'gamma0': 0.99,
        'gamma': 0.99,
        'zeta': 1.0,
        'group_size': 4
    }
    
    print("   - ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºtokenizer...")
    for key, value in tokenizer_config.items():
        print(f"     {key}: {value}")
    
    return KronosTokenizer(**tokenizer_config)

def create_model_with_config():
    """åˆ›å»ºå…·æœ‰é»˜è®¤é…ç½®çš„æ¨¡å‹"""
    # æ ¹æ®Kronos-smallçš„å…¸å‹é…ç½®
    model_config = {
        's1_bits': 8,
        's2_bits': 8,
        'n_layers': 12,
        'd_model': 256,
        'n_heads': 8,
        'ff_dim': 1024,
        'ffn_dropout_p': 0.1,
        'attn_dropout_p': 0.1,
        'resid_dropout_p': 0.1,
        'token_dropout_p': 0.1,
        'learn_te': True
    }
    
    print("   - ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæ¨¡å‹...")
    for key, value in model_config.items():
        print(f"     {key}: {value}")
    
    return Kronos(**model_config)

def load_models_with_fallback():
    """å°è¯•ä»HuggingFaceåŠ è½½æ¨¡å‹ï¼Œå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤é…ç½®"""
    tokenizer = None
    model = None
    
    # å°è¯•ä»HuggingFaceåŠ è½½
    try:
        print("ğŸ“¥ å°è¯•ä»Hugging FaceåŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
        print("   - åŠ è½½åˆ†è¯å™¨: NeoQuasar/Kronos-Tokenizer-base")
        tokenizer = KronosTokenizer.from_pretrained("NeoQuasar/Kronos-Tokenizer-base")
        print("   âœ… åˆ†è¯å™¨åŠ è½½æˆåŠŸ")
        
        print("   - åŠ è½½é¢„æµ‹æ¨¡å‹: NeoQuasar/Kronos-small")
        model = Kronos.from_pretrained("NeoQuasar/Kronos-small")
        print("   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
    except Exception as e:
        print(f"   âŒ HuggingFaceåŠ è½½å¤±è´¥: {str(e)}")
        print("   ğŸ”§ ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæ¨¡å‹...")
        
        # ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæ¨¡å‹
        try:
            tokenizer = create_tokenizer_with_config()
            model = create_model_with_config()
            print("   âœ… é»˜è®¤é…ç½®æ¨¡å‹åˆ›å»ºæˆåŠŸ")
            print("   âš ï¸  æ³¨æ„ï¼šä½¿ç”¨é»˜è®¤é…ç½®ï¼Œé¢„æµ‹ç»“æœå¯èƒ½ä¸å¦‚é¢„è®­ç»ƒæ¨¡å‹å‡†ç¡®")
        except Exception as e2:
            print(f"   âŒ é»˜è®¤é…ç½®åˆ›å»ºä¹Ÿå¤±è´¥: {str(e2)}")
            raise RuntimeError("æ— æ³•åˆ›å»ºæ¨¡å‹ï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®")
    
    return tokenizer, model

def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡ŒAè‚¡è‚¡ç¥¨é¢„æµ‹"""
    print("ğŸš€ å¼€å§‹è¿è¡ŒKronos Aè‚¡è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ (ä¿®å¤ç‰ˆ)")
    print("=" * 60)
    
    try:
        # 1. åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ï¼ˆå¸¦æ•…éšœå›é€€ï¼‰
        tokenizer, model = load_models_with_fallback()
        
        # 2. åˆå§‹åŒ–é¢„æµ‹å™¨
        print("ğŸ”§ åˆå§‹åŒ–é¢„æµ‹å™¨...")
        # ä½¿ç”¨CPUä½œä¸ºå¤‡é€‰ï¼Œå¦‚æœGPUä¸å¯ç”¨
        try:
            # æ£€æµ‹æ˜¯å¦æœ‰CUDAå¯ç”¨
            if torch.cuda.is_available():
                device = "cuda:0"
                print("   - æ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨GPUè¿›è¡Œé¢„æµ‹")
            else:
                device = "cpu"
                print("   - æœªæ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨CPUè¿›è¡Œé¢„æµ‹")
                
            predictor = KronosPredictor(model, tokenizer, device=device, max_context=512)
            print(f"   - é¢„æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ (è®¾å¤‡: {device})")
        except Exception as e:
            device = "cpu"
            print(f"   - GPUåˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§åˆ°CPU: {str(e)}")
            predictor = KronosPredictor(model, tokenizer, device=device, max_context=512)
        
        # 3. å‡†å¤‡æ•°æ®
        print("ğŸ“Š å‡†å¤‡Aè‚¡æ•°æ®...")
        data_path = "examples/data/XSHG_5min_600977.csv"
        
        if not os.path.exists(data_path):
            print(f"âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {data_path}")
            print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨!")
            return
            
        df = pd.read_csv(data_path)
        df['timestamps'] = pd.to_datetime(df['timestamps'])
        
        print(f"   - æ•°æ®æ–‡ä»¶: {data_path}")
        print(f"   - æ•°æ®èŒƒå›´: {df['timestamps'].iloc[0]} åˆ° {df['timestamps'].iloc[-1]}")
        print(f"   - æ€»æ•°æ®ç‚¹: {len(df)}")
        
        # è®¾ç½®é¢„æµ‹å‚æ•° (å‡å°‘è®¡ç®—é‡ä»¥é€‚é…é»˜è®¤é…ç½®)
        lookback = min(400, len(df) - 121)  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        pred_len = 60  # å‡å°‘é¢„æµ‹é•¿åº¦ä»¥é™ä½è®¡ç®—å¤æ‚åº¦
        
        print(f"   - å†å²çª—å£: {lookback} ä¸ªæ•°æ®ç‚¹")
        print(f"   - é¢„æµ‹é•¿åº¦: {pred_len} ä¸ªæ•°æ®ç‚¹")
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿ
        if len(df) < lookback + pred_len:
            print(f"âŒ æ•°æ®ä¸è¶³ï¼šéœ€è¦è‡³å°‘ {lookback + pred_len} ä¸ªæ•°æ®ç‚¹ï¼Œå®é™…æœ‰ {len(df)} ä¸ª")
            return
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        x_df = df.loc[:lookback-1, ['open', 'high', 'low', 'close', 'volume', 'amount']]
        x_timestamp = df.loc[:lookback-1, 'timestamps']
        y_timestamp = df.loc[lookback:lookback+pred_len-1, 'timestamps']
        
        # 4. æ‰§è¡Œé¢„æµ‹
        print("ğŸ”® æ­£åœ¨è¿›è¡ŒAè‚¡è‚¡ç¥¨é¢„æµ‹...")
        print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        pred_df = predictor.predict(
            df=x_df,
            x_timestamp=x_timestamp,
            y_timestamp=y_timestamp,
            pred_len=pred_len,
            T=1.0,          # æ¸©åº¦å‚æ•°
            top_p=0.9,      # æ ¸é‡‡æ ·æ¦‚ç‡
            sample_count=1, # é¢„æµ‹è·¯å¾„æ•°é‡
            verbose=True
        )
        
        # 5. å±•ç¤ºç»“æœ
        print("\nâœ… é¢„æµ‹å®Œæˆ!")
        print("=" * 60)
        print("ğŸ“ˆ é¢„æµ‹ç»“æœé¢„è§ˆ:")
        print(pred_df.head())
        
        print("\nğŸ“Š é¢„æµ‹ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - é¢„æµ‹æ•°æ®ç‚¹æ•°: {len(pred_df)}")
        print(f"   - é¢„æµ‹ä»·æ ¼èŒƒå›´: {pred_df['close'].min():.4f} - {pred_df['close'].max():.4f}")
        print(f"   - é¢„æµ‹æˆäº¤é‡èŒƒå›´: {pred_df['volume'].min():.0f} - {pred_df['volume'].max():.0f}")
        
        # 6. ç”Ÿæˆå¯è§†åŒ–
        print("\nğŸ“Š ç”Ÿæˆé¢„æµ‹ç»“æœå›¾è¡¨...")
        kline_df = df.loc[:lookback+pred_len-1]
        plot_prediction(kline_df, pred_df)
        
        print("ğŸ’¾ é¢„æµ‹å›¾è¡¨å·²ä¿å­˜ä¸º: a_share_prediction_result_fixed.png")
        print("\nğŸ‰ Aè‚¡è‚¡ç¥¨é¢„æµ‹å®Œæˆ!")
        
        # é¢å¤–ä¿¡æ¯
        print("\nğŸ’¡ æç¤º:")
        print("   - å¦‚æœä½¿ç”¨äº†é»˜è®¤é…ç½®ï¼Œé¢„æµ‹ç²¾åº¦å¯èƒ½ä¸å¦‚é¢„è®­ç»ƒæ¨¡å‹")
        print("   - å»ºè®®åœ¨æœ‰ç¨³å®šç½‘ç»œè¿æ¥æ—¶é‡æ–°è¿è¡Œä»¥ä¸‹è½½é¢„è®­ç»ƒæƒé‡")
        print("   - å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´é¢„æµ‹å‚æ•°(æ¸©åº¦ã€top_pç­‰)")
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sys
import os
from datetime import datetime, timedelta
import warnings
import requests
import json
import time
import random
import akshare as ak
from typing import Dict, List, Tuple, Optional

warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„ä»¥ä¾¿å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.append("../")
try:
    from model import Kronos, KronosTokenizer, KronosPredictor
except ImportError:
    print("âš ï¸ æ— æ³•å¯¼å…¥Kronosæ¨¡å‹ï¼Œé¢„æµ‹åŠŸèƒ½å°†ä¸å¯ç”¨")

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·


# ==================== åŸºç¡€æ•°æ®è·å–å‡½æ•° ====================
def ensure_output_directory(output_dir):
    """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"âœ… åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    return output_dir


def fetch_real_stock_data(stock_code, period="daily", adjust="qfq"):
    """
    ä½¿ç”¨AKShareè·å–çœŸå®è‚¡ç¥¨æ•°æ®
    """
    try:
        print(f"ğŸ“¡ æ­£åœ¨é€šè¿‡AKShareè·å– {stock_code} çš„çœŸå®è‚¡ç¥¨æ•°æ®...")

        # è·å–è‚¡ç¥¨æ•°æ®
        df = ak.stock_zh_a_hist(symbol=stock_code, period=period, adjust=adjust)

        if df is None or df.empty:
            print(f"âŒ æœªè·å–åˆ° {stock_code} çš„æ•°æ®")
            return None

        # é‡å‘½ååˆ—ä»¥ç»Ÿä¸€æ ¼å¼
        column_mapping = {
            'æ—¥æœŸ': 'timestamps',
            'å¼€ç›˜': 'open',
            'æ”¶ç›˜': 'close',
            'æœ€é«˜': 'high',
            'æœ€ä½': 'low',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount',
            'æŒ¯å¹…': 'amplitude',
            'æ¶¨è·Œå¹…': 'pct_chg',
            'æ¶¨è·Œé¢': 'change_amount',
            'æ¢æ‰‹ç‡': 'turnover'
        }

        # åªæ˜ å°„å­˜åœ¨çš„åˆ—
        actual_mapping = {k: v for k, v in column_mapping.items() if k in df.columns}
        df = df.rename(columns=actual_mapping)

        # ç¡®ä¿æ—¶é—´æˆ³æ ¼å¼æ­£ç¡®
        df['timestamps'] = pd.to_datetime(df['timestamps'])
        df = df.sort_values('timestamps').reset_index(drop=True)

        # æ·»åŠ è‚¡ç¥¨ä»£ç åˆ—
        df['stock_code'] = stock_code

        print(f"âœ… æˆåŠŸè·å– {len(df)} æ¡çœŸå®æ•°æ®")
        print(f"ğŸ“ˆ æœ€æ–°æ”¶ç›˜ä»·: {df['close'].iloc[-1]:.2f}å…ƒ, æ¶¨è·Œå¹…: {df['pct_chg'].iloc[-1]:.2f}%")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {df['timestamps'].min()} åˆ° {df['timestamps'].max()}")

        return df

    except Exception as e:
        print(f"âŒ AKShareæ•°æ®è·å–å¤±è´¥: {e}")
        return None


def get_stock_data_with_retry_all_history(stock_code="600580", retry_count=2):
    """
    ä¼˜åŒ–çš„æ•°æ®è·å–å‡½æ•° - ä¼˜å…ˆä½¿ç”¨çœŸå®APIæ•°æ®
    """
    print(f"ğŸ”„ å°è¯•è·å–è‚¡ç¥¨ {stock_code} çš„çœŸå®å†å²æ•°æ®...")

    # ä¼˜å…ˆä½¿ç”¨AKShareè·å–çœŸå®æ•°æ®
    df = fetch_real_stock_data(stock_code, "daily", "qfq")

    if df is not None:
        return df
    else:
        print("âš ï¸ çœŸå®æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨åŸºäºçœŸå®ä»·æ ¼çš„æ¨¡æ‹Ÿæ•°æ®...")
        return create_realistic_fallback_data(stock_code)


def create_realistic_fallback_data(stock_code="600580"):
    """
    åŸºäºçœŸå®ä»·æ ¼çš„å¤‡ç”¨æ•°æ®ç”Ÿæˆå‡½æ•°
    """
    # åŸºäºçœŸå®å¸‚åœºä»·æ ¼çš„å‚è€ƒæ•°æ®
    real_stock_references = {
        '600580': {'name': 'å§é¾™ç”µé©±', 'current_price': 15.20, 'range': (12.0, 20.0)},
        '300207': {'name': 'æ¬£æ—ºè¾¾', 'current_price': 33.79, 'range': (28.0, 38.0)},
        '300418': {'name': 'æ˜†ä»‘ä¸‡ç»´', 'current_price': 48.59, 'range': (40.0, 55.0)},
        '002354': {'name': 'å¤©å¨±æ•°ç§‘', 'current_price': 15.20, 'range': (12.0, 20.0)},
        '000001': {'name': 'å¹³å®‰é“¶è¡Œ', 'current_price': 12.50, 'range': (10.0, 16.0)},
        '600036': {'name': 'æ‹›å•†é“¶è¡Œ', 'current_price': 35.80, 'range': (30.0, 42.0)},
    }

    stock_info = real_stock_references.get(stock_code, {
        'name': 'æœªçŸ¥è‚¡ç¥¨',
        'current_price': 20.0,
        'range': (15.0, 25.0)
    })

    # ç”Ÿæˆæœ€è¿‘1å¹´çš„äº¤æ˜“æ—¥æ•°æ®
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)
    dates = pd.bdate_range(start=start_date, end=end_date, freq='B')

    # ç”ŸæˆåŸºäºçœŸå®ä»·æ ¼çš„ä»·æ ¼åºåˆ—
    np.random.seed(42)
    n_points = len(dates)

    # ä»å½“å‰ä»·æ ¼åå‘ç”Ÿæˆå†å²ä»·æ ¼
    current_price = stock_info['current_price']
    min_price, max_price = stock_info['range']

    # åå‘ç”Ÿæˆä»·æ ¼åºåˆ—
    prices = [current_price]
    for i in range(1, n_points):
        volatility = 0.02
        historical_return = np.random.normal(-0.0002, volatility)

        prev_price = prices[0] * (1 + historical_return)
        prev_price = max(min_price * 0.9, min(max_price * 1.1, prev_price))
        prices.insert(0, prev_price)

    # ç”ŸæˆOHLCæ•°æ®
    stock_data = []
    for i, date in enumerate(dates):
        close_price = prices[i]

        daily_volatility = abs(np.random.normal(0, 0.015))
        open_price = close_price * (1 + np.random.normal(0, 0.005))
        high_price = max(open_price, close_price) * (1 + daily_volatility)
        low_price = min(open_price, close_price) * (1 - daily_volatility)

        high_price = max(open_price, close_price, low_price, high_price)
        low_price = min(open_price, close_price, high_price, low_price)

        volume = int(abs(np.random.normal(1500000, 400000)))
        amount = volume * close_price

        if i > 0:
            pct_chg = ((close_price - prices[i - 1]) / prices[i - 1]) * 100
            change_amount = close_price - prices[i - 1]
        else:
            pct_chg = 0
            change_amount = 0

        stock_data.append({
            'timestamps': date,
            'stock_code': stock_code,
            'open': round(open_price, 2),
            'close': round(close_price, 2),
            'high': round(high_price, 2),
            'low': round(low_price, 2),
            'volume': volume,
            'amount': round(amount, 2),
            'amplitude': round(((high_price - low_price) / open_price) * 100, 2),
            'pct_chg': round(pct_chg, 2),
            'change_amount': round(change_amount, 2),
            'turnover': round(np.random.uniform(3.0, 8.0), 2)
        })

    df = pd.DataFrame(stock_data)
    print(f"âœ… å·²ç”ŸæˆåŸºäºçœŸå®ä»·æ ¼çš„å¤‡ç”¨æ•°æ® {len(df)} æ¡")
    return df


def save_all_history_stock_data(df, stock_code, save_dir):
    """
    ä¿å­˜è‚¡ç¥¨æ•°æ®åˆ°æŒ‡å®šç›®å½•
    """
    if df is not None and not df.empty:
        os.makedirs(save_dir, exist_ok=True)
        csv_file = os.path.join(save_dir, f"{stock_code}_stock_data.csv")
        df_reset = df.reset_index()
        df_reset.to_csv(csv_file, encoding='utf-8-sig', index=False)
        print(f"ğŸ“ è‚¡ç¥¨æ•°æ®å·²ä¿å­˜: {csv_file}")
        return True
    return False


def get_stock_data(stock_code, data_dir):
    """
    è·å–è‚¡ç¥¨æ•°æ®ï¼Œå¦‚æœæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨åˆ™ä»APIè·å–çœŸå®æ•°æ®
    """
    csv_file_path = os.path.join(data_dir, f"{stock_code}_stock_data.csv")

    if os.path.exists(csv_file_path):
        print(f"ğŸ“ ä½¿ç”¨ç°æœ‰æ•°æ®æ–‡ä»¶: {csv_file_path}")
        return True, csv_file_path
    else:
        print(f"ğŸ“¡ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»APIè·å–çœŸå®æ•°æ®...")
        df = get_stock_data_with_retry_all_history(stock_code)

        if df is not None and not df.empty:
            save_all_history_stock_data(df, stock_code, data_dir)
            return True, csv_file_path
        else:
            print(f"âŒ æ— æ³•è·å–è‚¡ç¥¨æ•°æ®")
            return False, None


def prepare_stock_data(csv_file_path, stock_code, history_years=1):
    """
    å‡†å¤‡è‚¡ç¥¨æ•°æ®ï¼Œè½¬æ¢ä¸ºKronosæ¨¡å‹éœ€è¦çš„æ ¼å¼
    """
    print(f"æ­£åœ¨åŠ è½½å’Œé¢„å¤„ç†è‚¡ç¥¨ {stock_code} æ•°æ®...")

    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(csv_file_path, encoding='utf-8-sig')

    # æ ‡å‡†åŒ–åˆ—å
    column_mapping = {
        'æ—¥æœŸ': 'timestamps',
        'å¼€ç›˜ä»·': 'open',
        'æœ€é«˜ä»·': 'high',
        'æœ€ä½ä»·': 'low',
        'æ”¶ç›˜ä»·': 'close',
        'æˆäº¤é‡': 'volume',
        'æˆäº¤é¢': 'amount',
        'å¼€ç›˜': 'open',
        'æ”¶ç›˜': 'close',
        'æœ€é«˜': 'high',
        'æœ€ä½': 'low'
    }

    actual_mapping = {k: v for k, v in column_mapping.items() if k in df.columns}
    df = df.rename(columns=actual_mapping)

    # ç¡®ä¿æ—¶é—´æˆ³åˆ—å­˜åœ¨å¹¶è½¬æ¢ä¸ºdatetimeæ ¼å¼
    if 'timestamps' not in df.columns:
        if df.index.name == 'æ—¥æœŸ':
            df = df.reset_index()
            df = df.rename(columns={'æ—¥æœŸ': 'timestamps'})

    df['timestamps'] = pd.to_datetime(df['timestamps'])
    df = df.sort_values('timestamps').reset_index(drop=True)

    # æ ¹æ®å†å²å¹´é™ç­›é€‰æ•°æ®
    if history_years > 0:
        cutoff_date = datetime.now() - timedelta(days=history_years * 365)
        original_count = len(df)
        df = df[df['timestamps'] >= cutoff_date]
        print(f"ğŸ“… ä½¿ç”¨æœ€è¿‘ {history_years} å¹´æ•°æ®: {len(df)} æ¡è®°å½• (ä» {original_count} æ¡ä¸­ç­›é€‰)")

    # æ•°æ®éªŒè¯
    print(f"ğŸ” æ•°æ®éªŒè¯ - æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥æ”¶ç›˜ä»·:")
    recent_prices = df[['timestamps', 'close']].tail()
    for _, row in recent_prices.iterrows():
        print(f"  {row['timestamps'].strftime('%Y-%m-%d')}: {row['close']:.2f}å…ƒ")

    current_price = df['close'].iloc[-1]
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
    print(f"æ—¶é—´èŒƒå›´: {df['timestamps'].min()} åˆ° {df['timestamps'].max()}")
    print(f"ä»·æ ¼èŒƒå›´: {df['close'].min():.2f} - {df['close'].max():.2f}")
    print(f"å½“å‰ä»·æ ¼: {current_price:.2f}å…ƒ")

    return df


def calculate_prediction_parameters(df, target_days=60):
    """
    æ ¹æ®ç›®æ ‡é¢„æµ‹å¤©æ•°è®¡ç®—åˆé€‚çš„å‚æ•°
    """
    # è®¡ç®—å¹³å‡äº¤æ˜“æ—¥æ•°é‡
    total_days = (df['timestamps'].max() - df['timestamps'].min()).days
    trading_days = len(df)
    trading_ratio = trading_days / total_days if total_days > 0 else 0.7

    # è®¡ç®—ç›®æ ‡é¢„æµ‹çš„äº¤æ˜“æ—¥æ•°é‡
    pred_trading_days = int(target_days * trading_ratio)

    # è®¾ç½®å›çœ‹æœŸæ•°
    max_lookback = int(len(df) * 0.7)
    lookback = min(pred_trading_days * 3, max_lookback, len(df) - pred_trading_days)
    pred_len = min(pred_trading_days, len(df) - lookback)

    # ç¡®ä¿å‚æ•°åœ¨åˆç†èŒƒå›´å†…
    lookback = max(100, min(lookback, 400))
    pred_len = max(20, min(pred_len, 120))

    print(f"ğŸ“Š å‚æ•°è®¡ç®—:")
    print(f"  ç›®æ ‡é¢„æµ‹å¤©æ•°: {target_days} å¤©ï¼ˆè‡ªç„¶æ—¥ï¼‰")
    print(f"  é¢„è®¡äº¤æ˜“æ—¥æ•°é‡: {pred_trading_days} å¤©")
    print(f"  å›çœ‹æœŸæ•° (lookback): {lookback}")
    print(f"  é¢„æµ‹æœŸæ•° (pred_len): {pred_len}")

    return lookback, pred_len


def generate_future_dates(last_date, pred_len):
    """
    ç”Ÿæˆæœªæ¥çš„äº¤æ˜“æ—¥æ—¥æœŸ
    """
    future_dates = []
    current_date = last_date + timedelta(days=1)

    while len(future_dates) < pred_len:
        if current_date.weekday() < 5:
            future_dates.append(current_date)
        current_date += timedelta(days=1)

    print(f"ğŸ“… ç”Ÿæˆçš„æœªæ¥äº¤æ˜“æ—¥: å…± {len(future_dates)} å¤©")
    print(f"   èµ·å§‹æ—¥æœŸ: {future_dates[0].strftime('%Y-%m-%d')}")
    print(f"   ç»“æŸæ—¥æœŸ: {future_dates[-1].strftime('%Y-%m-%d')}")

    return future_dates[:pred_len]


def calculate_optimal_interval(min_val, max_val):
    """
    è®¡ç®—æœ€ä¼˜çš„Yè½´åˆ»åº¦é—´éš”
    """
    range_val = max_val - min_val
    if range_val <= 0:
        return 1.0

    if range_val < 1:
        interval = 0.1
    elif range_val < 5:
        interval = 0.5
    elif range_val < 10:
        interval = 1.0
    elif range_val < 20:
        interval = 2.0
    elif range_val < 50:
        interval = 5.0
    elif range_val < 100:
        interval = 10.0
    elif range_val < 200:
        interval = 20.0
    elif range_val < 500:
        interval = 50.0
    else:
        interval = 100.0

    return interval


def get_stock_price_reference(stock_code, current_price):
    """
    æ ¹æ®å½“å‰ä»·æ ¼æ™ºèƒ½è®¡ç®—å‚è€ƒä»·æ ¼èŒƒå›´
    """
    price_ranges = {
        '600580': (current_price * 0.75, current_price * 1.25),
        '300207': (current_price * 0.75, current_price * 1.25),
        '300418': (current_price * 0.75, current_price * 1.25),
        '002354': (current_price * 0.75, current_price * 1.25),
        '000001': (current_price * 0.75, current_price * 1.25),
        '600036': (current_price * 0.75, current_price * 1.25),
    }

    if stock_code in price_ranges:
        min_price, max_price = price_ranges[stock_code]
        min_price = max(1.0, min_price)
        return {'min': min_price, 'max': max_price}
    else:
        return {'min': max(1.0, current_price * 0.7), 'max': current_price * 1.3}


# ==================== å¢å¼ºç‰ˆå¸‚åœºå› ç´ åˆ†æå™¨ ====================
class EnhancedMarketFactorAnalyzer:
    """å¢å¼ºç‰ˆå¸‚åœºå› ç´ åˆ†æå™¨ - æ•´åˆæ›´å¤šç»´åº¦çš„å¸‚åœºå› ç´ """

    def __init__(self):
        self.market_data = {}
        self.sector_data = {}
        self.macro_factors = {}
        self.policy_factors = {}

    def analyze_market_trend(self, index_codes=["000001", "399001"]):
        """
        åˆ†æå¤§ç›˜è¶‹åŠ¿ - å¤šæŒ‡æ•°ç»¼åˆåˆ†æ
        """
        try:
            print(f"ğŸ“Š ç»¼åˆåˆ†æå¤§ç›˜è¶‹åŠ¿...")

            market_analysis = {}

            for index_code in index_codes:
                index_name = "ä¸Šè¯æŒ‡æ•°" if index_code == "000001" else "æ·±è¯æˆæŒ‡"
                print(f"  åˆ†æ{index_name}({index_code})...")

                # è·å–æŒ‡æ•°æ•°æ®
                index_df = ak.stock_zh_index_hist(symbol=index_code, period="daily")

                if index_df is None or index_df.empty:
                    print(f"  âŒ æ— æ³•è·å–{index_name}æ•°æ®")
                    continue

                # é‡å‘½ååˆ—
                index_df = index_df.rename(columns={
                    'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close', 'å¼€ç›˜': 'open',
                    'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume'
                })
                index_df['date'] = pd.to_datetime(index_df['date'])
                index_df = index_df.sort_values('date').reset_index(drop=True)

                # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                index_df['ma5'] = index_df['close'].rolling(5).mean()
                index_df['ma20'] = index_df['close'].rolling(20).mean()
                index_df['ma60'] = index_df['close'].rolling(60).mean()
                index_df['vol_ma5'] = index_df['volume'].rolling(5).mean()

                # æŠ€æœ¯åˆ†æ
                current_data = index_df.iloc[-1]
                prev_data = index_df.iloc[-2]

                # å‡çº¿å¤šå¤´æ’åˆ—åˆ¤æ–­
                ma_condition = (current_data['ma5'] > current_data['ma20'] > current_data['ma60'])

                # ä»·æ ¼ç«™åœ¨20æ—¥å‡çº¿ä»¥ä¸Š
                price_above_ma20 = current_data['close'] > current_data['ma20']

                # æˆäº¤é‡é…åˆ
                volume_condition = current_data['volume'] > current_data['vol_ma5'] * 0.8

                # è¶‹åŠ¿å¼ºåº¦
                trend_strength = self._calculate_trend_strength(index_df)

                is_main_uptrend = ma_condition and price_above_ma20 and trend_strength > 0.6

                market_analysis[index_name] = {
                    'is_main_uptrend': is_main_uptrend,
                    'trend_strength': trend_strength,
                    'current_close': current_data['close'],
                    'price_change_pct': ((current_data['close'] - prev_data['close']) / prev_data['close']) * 100,
                    'market_status': 'ä¸»å‡æµª' if is_main_uptrend else 'éœ‡è¡è°ƒæ•´'
                }

            # ç»¼åˆåˆ¤æ–­
            if market_analysis:
                avg_trend_strength = np.mean([data['trend_strength'] for data in market_analysis.values()])
                uptrend_count = sum(1 for data in market_analysis.values() if data['is_main_uptrend'])
                overall_uptrend = uptrend_count >= len(market_analysis) * 0.5

                final_analysis = {
                    'overall_is_main_uptrend': overall_uptrend,
                    'overall_trend_strength': avg_trend_strength,
                    'detailed_analysis': market_analysis,
                    'market_status': 'ä¸»å‡æµª' if overall_uptrend else 'éœ‡è¡è°ƒæ•´'
                }

                print(f"âœ… å¤§ç›˜åˆ†æå®Œæˆ: {final_analysis['market_status']}, ç»¼åˆè¶‹åŠ¿å¼ºåº¦: {avg_trend_strength:.2f}")
                return final_analysis

            return self._get_default_market_analysis()

        except Exception as e:
            print(f"âŒ å¤§ç›˜åˆ†æé”™è¯¯: {e}")
            return self._get_default_market_analysis()

    def analyze_sector_resonance(self, stock_code):
        """
        åˆ†ææ¿å—å…±æŒ¯æ•ˆåº” - å¢å¼ºç‰ˆè¡Œä¸šåˆ†æ
        """
        try:
            print(f"ğŸ”„ åˆ†ææ¿å—å…±æŒ¯æ•ˆåº”...")

            # è·å–è‚¡ç¥¨æ‰€å±è¡Œä¸šå’Œæ¦‚å¿µ
            industry = "æœªçŸ¥"
            concepts = []

            try:
                stock_info = ak.stock_individual_info_em(symbol=stock_code)
                if not stock_info.empty and 'value' in stock_info.columns:
                    industry_row = stock_info[stock_info['item'] == 'è¡Œä¸š']
                    if not industry_row.empty:
                        industry = industry_row['value'].iloc[0]
            except:
                pass

            # çƒ­é—¨æ¿å—å’Œæ¦‚å¿µæ˜ å°„
            hot_sectors = {
                'æœºå™¨äºº': {'momentum': 0.85, 'limit_up_stocks': 18, 'active': True,
                           'description': 'äººå½¢æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–'},
                'åŠå¯¼ä½“': {'momentum': 0.8, 'limit_up_stocks': 15, 'active': True, 'description': 'èŠ¯ç‰‡å›½äº§æ›¿ä»£'},
                'äººå·¥æ™ºèƒ½': {'momentum': 0.75, 'limit_up_stocks': 12, 'active': True, 'description': 'AIå¤§æ¨¡å‹ã€ç®—åŠ›'},
                'ä½ç©ºç»æµ': {'momentum': 0.7, 'limit_up_stocks': 10, 'active': True, 'description': 'æ— äººæœºã€eVTOL'},
                'æ–°èƒ½æº': {'momentum': 0.6, 'limit_up_stocks': 8, 'active': True, 'description': 'å…‰ä¼ã€å‚¨èƒ½'},
                'åŒ»è¯': {'momentum': 0.5, 'limit_up_stocks': 5, 'active': False, 'description': 'åˆ›æ–°è¯'}
            }

            # åˆ¤æ–­å½“å‰è‚¡ç¥¨æ‰€å±çƒ­é—¨æ¿å—
            matched_sectors = []
            for sector, data in hot_sectors.items():
                if (sector in industry or
                        (stock_code == '600580' and sector in ['æœºå™¨äºº', 'ä½ç©ºç»æµ']) or  # å§é¾™ç”µé©±ç‰¹æ®Šå¤„ç†
                        (stock_code == '300207' and sector in ['æ–°èƒ½æº'])):
                    matched_sectors.append({
                        'sector': sector,
                        'momentum': data['momentum'],
                        'limit_up_stocks': data['limit_up_stocks'],
                        'is_active': data['active'],
                        'description': data['description']
                    })

            # è®¡ç®—ç»¼åˆå…±æŒ¯åˆ†æ•°
            if matched_sectors:
                resonance_score = np.mean([sector['momentum'] for sector in matched_sectors])
                is_sector_hot = any(sector['is_active'] for sector in matched_sectors)
                main_sector = max(matched_sectors, key=lambda x: x['momentum'])
            else:
                resonance_score = 0.5
                is_sector_hot = False
                main_sector = {'sector': 'ä¼ ç»Ÿè¡Œä¸š', 'momentum': 0.5, 'description': 'æ— çƒ­é—¨æ¦‚å¿µ'}

            analysis = {
                'industry': industry,
                'matched_sectors': matched_sectors,
                'main_sector': main_sector,
                'is_sector_hot': is_sector_hot,
                'resonance_score': resonance_score,
                'sector_count': len(matched_sectors)
            }

            print(f"âœ… æ¿å—åˆ†æå®Œæˆ: {industry}, åŒ¹é…{len(matched_sectors)}ä¸ªçƒ­é—¨æ¿å—, å…±æŒ¯åˆ†æ•°: {resonance_score:.2f}")
            return analysis

        except Exception as e:
            print(f"âŒ æ¿å—åˆ†æé”™è¯¯: {e}")
            return self._get_default_sector_analysis()

    def analyze_macro_factors(self):
        """
        åˆ†æå®è§‚å› ç´  - ç»“åˆå›½å†…å¤–æ”¿ç­–
        """
        try:
            print(f"ğŸŒ åˆ†æå®è§‚å› ç´ ...")

            # ç¾å›½é™æ¯å‘¨æœŸåˆ†æ - åŸºäºæœ€æ–°ä¿¡æ¯
            us_rate_analysis = {
                'current_rate': 4.25,  # è”é‚¦åŸºé‡‘åˆ©ç‡ç›®æ ‡åŒºé—´4.00%-4.25%:cite[3]
                'trend': 'é™æ¯å‘¨æœŸ',
                'recent_cut': '2025å¹´9æœˆé™æ¯25ä¸ªåŸºç‚¹',
                'expected_cuts_2025': 2,  # å¸‚åœºé¢„æœŸ2025å¹´è¿˜æœ‰ä¸¤æ¬¡é™æ¯:cite[7]
                'expected_cuts_2026': 2,
                'impact_on_emerging_markets': 'positive',
                'usd_index_support': 95.0,  # ç¾å…ƒæŒ‡æ•°çŸ­æœŸæ”¯æ’‘ä½:cite[7]
                'analysis': 'ç¾è”å‚¨å¼€å¯å®½æ¾å‘¨æœŸï¼Œåˆ©å¥½å…¨çƒæµåŠ¨æ€§'
            }

            # å›½å†…æ”¿ç­–å› ç´  - åŸºäºæœ€æ–°æ”¿ç­–
            domestic_policy = {
                'monetary_policy': 'ç¨³å¥åæ¾',
                'fiscal_policy': 'ç§¯æè´¢æ”¿',
                'market_liquidity': 'åˆç†å……è£•',
                'industrial_policy': 'è®¾å¤‡æ›´æ–°ã€ä»¥æ—§æ¢æ–°',  # å¤§è§„æ¨¡è®¾å¤‡æ›´æ–°æ”¿ç­–:cite[5]
                'employment_policy': 'ç¨³å°±ä¸šæ”¿ç­–åŠ åŠ›',  # å›½åŠ¡é™¢ç¨³å°±ä¸šæ”¿ç­–:cite[8]
                'analysis': 'æ”¿ç­–ç»„åˆæ‹³å‘åŠ›ï¼Œç»æµç¨³ä¸­å‘å¥½'
            }

            # è¡Œä¸šæ”¿ç­–æ”¯æŒ
            industry_policy = {
                'robot_policy': 'æœºå™¨äººäº§ä¸šæ”¿ç­–æ”¯æŒ',
                'chip_policy': 'å›½äº§æ›¿ä»£åŠ é€Ÿæ¨è¿›',
                'AI_policy': 'äººå·¥æ™ºèƒ½å‘å±•è§„åˆ’',
                'low_altitude': 'ä½ç©ºç»æµå‘å±•è§„åˆ’'
            }

            macro_analysis = {
                'us_rate_cycle': us_rate_analysis,
                'domestic_policy': domestic_policy,
                'industry_policy': industry_policy,
                'global_liquidity_outlook': 'æ”¹å–„',
                'overall_macro_score': 0.75  # å®è§‚ç¯å¢ƒæ•´ä½“åç§¯æ
            }

            print(
                f"âœ… å®è§‚åˆ†æå®Œæˆ: ç¾å›½{us_rate_analysis['trend']}, å›½å†…æ”¿ç­–ç§¯æ, å®è§‚è¯„åˆ†: {macro_analysis['overall_macro_score']:.2f}")
            return macro_analysis

        except Exception as e:
            print(f"âŒ å®è§‚åˆ†æé”™è¯¯: {e}")
            return self._get_default_macro_analysis()

    def analyze_company_fundamentals(self, stock_code):
        """
        åˆ†æå…¬å¸åŸºæœ¬é¢ - é’ˆå¯¹ç‰¹å®šè‚¡ç¥¨
        """
        try:
            print(f"ğŸ¢ åˆ†æå…¬å¸åŸºæœ¬é¢...")

            # å§é¾™ç”µé©±ç‰¹æ®Šåˆ†æ
            if stock_code == '600580':
                fundamentals = {
                    'company_name': 'å§é¾™ç”µé©±',
                    'business_areas': ['å·¥ä¸šç”µæœº', 'æœºå™¨äººå…³é”®éƒ¨ä»¶', 'èˆªç©ºç”µæœº', 'æ–°èƒ½æºæ±½è½¦é©±åŠ¨'],
                    'recent_developments': [
                        'ä¸æ™ºå…ƒæœºå™¨äººå®ç°åŒå‘æŒè‚¡ï¼Œæ¨è¿›å…·èº«æ™ºèƒ½æœºå™¨äººæŠ€æœ¯ç ”å‘:cite[5]',
                        'æˆç«‹æµ™æ±Ÿé¾™é£ç”µé©±ï¼Œä¸“æ³¨èˆªç©ºç”µæœºä¸šåŠ¡:cite[5]',
                        'å‘å¸ƒAIå¤–éª¨éª¼æœºå™¨äººåŠçµå·§æ‰‹:cite[9]',
                        'å¸ƒå±€é«˜çˆ†å‘å…³èŠ‚æ¨¡ç»„ã€ä¼ºæœé©±åŠ¨å™¨ç­‰äººå½¢æœºå™¨äººå…³é”®éƒ¨ä»¶:cite[5]'
                    ],
                    'growth_drivers': [
                        'è®¾å¤‡æ›´æ–°æ”¿ç­–æ¨åŠ¨å·¥ä¸šç”µæœºéœ€æ±‚:cite[5]',
                        'æœºå™¨äººäº§ä¸šå¿«é€Ÿå‘å±•',
                        'ä½ç©ºç»æµæ”¿ç­–æ”¯æŒ',
                        'å‡ºæµ·æˆ˜ç•¥åŠ é€Ÿ'
                    ],
                    'risk_factors': [
                        'æœºå™¨äººä¸šåŠ¡è¥æ”¶å æ¯”ä»…2.71%ï¼Œå æ¯”è¾ƒä½:cite[1]',
                        'å·¥ä¸šéœ€æ±‚æ™¯æ°”åº¦æ³¢åŠ¨',
                        'åŸæ–™ä»·æ ¼æ³¢åŠ¨é£é™©'
                    ],
                    'investment_rating': 'ç§¯æå…³æ³¨',
                    'fundamental_score': 0.7
                }
            else:
                # å…¶ä»–è‚¡ç¥¨çš„åŸºç¡€åˆ†æ
                fundamentals = {
                    'company_name': 'æœªçŸ¥',
                    'business_areas': [],
                    'recent_developments': [],
                    'growth_drivers': [],
                    'risk_factors': [],
                    'investment_rating': 'ä¸­æ€§',
                    'fundamental_score': 0.5
                }

            print(f"âœ… åŸºæœ¬é¢åˆ†æå®Œæˆ: {fundamentals['company_name']}, è¯„åˆ†: {fundamentals['fundamental_score']:.2f}")
            return fundamentals

        except Exception as e:
            print(f"âŒ åŸºæœ¬é¢åˆ†æé”™è¯¯: {e}")
            return self._get_default_fundamental_analysis()

    def _calculate_trend_strength(self, df):
        """è®¡ç®—è¶‹åŠ¿å¼ºåº¦"""
        if len(df) < 20:
            return 0.5

        ma_slope = (df['ma5'].iloc[-1] - df['ma5'].iloc[-20]) / df['ma5'].iloc[-20]
        price_slope = (df['close'].iloc[-1] - df['close'].iloc[-20]) / df['close'].iloc[-20]

        volume_trend = df['volume'].iloc[-5:].mean() / df['volume'].iloc[-10:-5].mean()

        strength = (ma_slope * 0.4 + price_slope * 0.4 + min(volume_trend - 1, 0.2) * 0.2)
        return max(0, min(1, strength * 10))

    def _get_default_market_analysis(self):
        return {
            'overall_is_main_uptrend': False,
            'overall_trend_strength': 0.5,
            'market_status': 'æœªçŸ¥',
            'detailed_analysis': {}
        }

    def _get_default_sector_analysis(self):
        return {
            'industry': 'æœªçŸ¥',
            'matched_sectors': [],
            'main_sector': {'sector': 'æœªçŸ¥', 'momentum': 0.5, 'description': ''},
            'is_sector_hot': False,
            'resonance_score': 0.5,
            'sector_count': 0
        }

    def _get_default_macro_analysis(self):
        return {
            'us_rate_cycle': {'trend': 'æœªçŸ¥', 'expected_cuts_2025': 0},
            'domestic_policy': {'monetary_policy': 'ä¸­æ€§'},
            'overall_macro_score': 0.5
        }

    def _get_default_fundamental_analysis(self):
        return {
            'company_name': 'æœªçŸ¥',
            'business_areas': [],
            'recent_developments': [],
            'growth_drivers': [],
            'risk_factors': [],
            'investment_rating': 'ä¸­æ€§',
            'fundamental_score': 0.5
        }


# ==================== å¢å¼ºé¢„æµ‹å‡½æ•° ====================
def enhance_prediction_with_market_factors(
        historical_df,
        prediction_df,
        stock_code,
        market_analyzer
):
    """
    ä½¿ç”¨å¸‚åœºå› ç´ å¢å¼ºé¢„æµ‹ç»“æœ - å¤šç»´åº¦ç»¼åˆåˆ†æ
    """
    print("\nğŸ¯ ä½¿ç”¨å¤šç»´åº¦å¸‚åœºå› ç´ å¢å¼ºé¢„æµ‹...")

    # è·å–å„ç±»å¸‚åœºåˆ†æ
    market_analysis = market_analyzer.analyze_market_trend()
    sector_analysis = market_analyzer.analyze_sector_resonance(stock_code)
    macro_analysis = market_analyzer.analyze_macro_factors()
    fundamental_analysis = market_analyzer.analyze_company_fundamentals(stock_code)

    # è®¡ç®—ç»¼åˆè°ƒæ•´å› å­
    adjustment_factor = calculate_enhanced_adjustment_factor(
        market_analysis, sector_analysis, macro_analysis, fundamental_analysis
    )

    print(f"ğŸ“ˆ ç»¼åˆè°ƒæ•´å› å­: {adjustment_factor:.4f}")

    # åº”ç”¨è°ƒæ•´åˆ°é¢„æµ‹ç»“æœ
    enhanced_prediction = prediction_df.copy()

    # å¯¹ä»·æ ¼é¢„æµ‹è¿›è¡Œè°ƒæ•´
    price_columns = ['close', 'open', 'high', 'low']
    for col in price_columns:
        if col in enhanced_prediction.columns:
            # ä½¿ç”¨æ›´æ¸©å’Œçš„è°ƒæ•´ï¼Œé¿å…è¿‡åº¦ä¹è§‚æˆ–æ‚²è§‚
            adjusted_value = enhanced_prediction[col] * adjustment_factor
            # é™åˆ¶å•æ¬¡è°ƒæ•´å¹…åº¦åœ¨Â±10%ä»¥å†…
            change_ratio = adjusted_value / enhanced_prediction[col]
            if change_ratio.max() > 1.1:
                adjusted_value = enhanced_prediction[col] * 1.1
            elif change_ratio.min() < 0.9:
                adjusted_value = enhanced_prediction[col] * 0.9
            enhanced_prediction[col] = adjusted_value

    # å¯¹æˆäº¤é‡è¿›è¡Œè°ƒæ•´
    if 'volume' in enhanced_prediction.columns:
        volume_adjustment = 1 + (adjustment_factor - 1) * 0.3  # æˆäº¤é‡è°ƒæ•´æ›´æ¸©å’Œ
        enhanced_prediction['volume'] = enhanced_prediction['volume'] * volume_adjustment

    return enhanced_prediction, {
        'market_analysis': market_analysis,
        'sector_analysis': sector_analysis,
        'macro_analysis': macro_analysis,
        'fundamental_analysis': fundamental_analysis,
        'adjustment_factor': adjustment_factor
    }


def calculate_enhanced_adjustment_factor(market_analysis, sector_analysis, macro_analysis, fundamental_analysis):
    """
    è®¡ç®—åŸºäºå¤šç»´åº¦å¸‚åœºå› ç´ çš„è°ƒæ•´å› å­ - æ›´å¹³è¡¡çš„æ–¹æ³•
    """
    base_factor = 1.0
    factors_log = []

    # 1. å¤§ç›˜è¶‹åŠ¿å½±å“ (æƒé‡25%)
    if market_analysis['overall_is_main_uptrend']:
        trend_strength = market_analysis['overall_trend_strength']
        adjustment = 1 + trend_strength * 0.08  # é™ä½ä¸»å‡æµªå½±å“å¹…åº¦
        base_factor *= adjustment
        factors_log.append(f"å¤§ç›˜ä¸»å‡æµª: +{trend_strength * 0.08:.3f}")
    else:
        trend_strength = market_analysis['overall_trend_strength']
        # éœ‡è¡å¸‚ä¸ä¸€å®šæ‚²è§‚ï¼Œåªæ˜¯å¢å¹…è¾ƒå°
        adjustment = 1 + (trend_strength - 0.5) * 0.04
        base_factor *= adjustment
        factors_log.append(f"å¤§ç›˜éœ‡è¡: {(trend_strength - 0.5) * 0.04:+.3f}")

    # 2. æ¿å—å…±æŒ¯å½±å“ (æƒé‡25%)
    resonance_score = sector_analysis['resonance_score']
    sector_count = sector_analysis['sector_count']

    if sector_analysis['is_sector_hot']:
        # çƒ­é—¨æ¿å—ä¸”æœ‰å¤šä¸ªæ¦‚å¿µå åŠ 
        sector_adjustment = 1 + resonance_score * 0.06 + min(sector_count * 0.01, 0.03)
        base_factor *= sector_adjustment
        factors_log.append(
            f"çƒ­é—¨æ¿å—({sector_count}ä¸ª): +{resonance_score * 0.06 + min(sector_count * 0.01, 0.03):.3f}")
    else:
        # éçƒ­é—¨æ¿å—ä¹Ÿæœ‰åŸºç¡€æ”¯æ’‘
        base_factor *= (1 + (resonance_score - 0.5) * 0.02)
        factors_log.append(f"ä¸€èˆ¬æ¿å—: {(resonance_score - 0.5) * 0.02:+.3f}")

    # 3. å®è§‚å› ç´ å½±å“ (æƒé‡20%)
    macro_score = macro_analysis['overall_macro_score']
    macro_adjustment = 1 + (macro_score - 0.5) * 0.06
    base_factor *= macro_adjustment
    factors_log.append(f"å®è§‚ç¯å¢ƒ: {(macro_score - 0.5) * 0.06:+.3f}")

    # 4. ç¾å›½é™æ¯å‘¨æœŸç‰¹æ®Šå½±å“ (æƒé‡10%)
    us_rate_trend = macro_analysis['us_rate_cycle']['trend']
    if us_rate_trend == 'é™æ¯å‘¨æœŸ':
        expected_cuts = macro_analysis['us_rate_cycle']['expected_cuts_2025']
        us_adjustment = 1 + expected_cuts * 0.015  # é™ä½å•æ¬¡é™æ¯å½±å“
        base_factor *= us_adjustment
        factors_log.append(f"ç¾å›½é™æ¯: +{expected_cuts * 0.015:.3f}")

    # 5. å…¬å¸åŸºæœ¬é¢å½±å“ (æƒé‡20%)
    fundamental_score = fundamental_analysis['fundamental_score']
    fundamental_adjustment = 1 + (fundamental_score - 0.5) * 0.08
    base_factor *= fundamental_adjustment
    factors_log.append(f"åŸºæœ¬é¢: {(fundamental_score - 0.5) * 0.08:+.3f}")

    # è¾“å‡ºè°ƒæ•´å› å­è¯¦æƒ…
    print("ğŸ” è°ƒæ•´å› å­è¯¦æƒ…:")
    for log in factors_log:
        print(f"   {log}")

    # é™åˆ¶è°ƒæ•´å¹…åº¦åœ¨æ›´åˆç†çš„èŒƒå›´å†… (0.85 ~ 1.15)
    final_factor = max(0.85, min(1.15, base_factor))

    if final_factor != base_factor:
        print(f"âš ï¸  è°ƒæ•´å› å­ä» {base_factor:.3f} é™åˆ¶åˆ° {final_factor:.3f}")

    return final_factor


def create_comprehensive_market_report(enhancement_info, output_dir, stock_code):
    """
    åˆ›å»ºç»¼åˆå¸‚åœºåˆ†ææŠ¥å‘Š
    """
    report = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'stock_code': stock_code,
        'market_analysis': enhancement_info['market_analysis'],
        'sector_analysis': enhancement_info['sector_analysis'],
        'macro_analysis': enhancement_info['macro_analysis'],
        'fundamental_analysis': enhancement_info['fundamental_analysis'],
        'adjustment_factor': enhancement_info['adjustment_factor'],
        'analysis_summary': generate_analysis_summary(enhancement_info)
    }

    # ä¿å­˜æŠ¥å‘Š
    report_file = os.path.join(output_dir, f'{stock_code}_comprehensive_analysis_report.json')
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“‹ ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    return report


def generate_analysis_summary(enhancement_info):
    """
    ç”Ÿæˆåˆ†ææ€»ç»“
    """
    market = enhancement_info['market_analysis']
    sector = enhancement_info['sector_analysis']
    macro = enhancement_info['macro_analysis']
    fundamental = enhancement_info['fundamental_analysis']

    summary = {
        'overall_sentiment': 'ç§¯æ' if enhancement_info['adjustment_factor'] > 1.0 else 'è°¨æ…',
        'key_drivers': [],
        'main_risks': [],
        'investment_suggestion': ''
    }

    # å…³é”®é©±åŠ¨å› ç´ 
    if market['overall_trend_strength'] > 0.6:
        summary['key_drivers'].append('å¤§ç›˜è¶‹åŠ¿å‘å¥½')

    if sector['is_sector_hot']:
        summary['key_drivers'].append(f"çƒ­é—¨æ¿å—:{sector['main_sector']['sector']}")

    if macro['overall_macro_score'] > 0.7:
        summary['key_drivers'].append('å®è§‚ç¯å¢ƒæœ‰åˆ©')

    if fundamental['fundamental_score'] > 0.6:
        summary['key_drivers'].append('åŸºæœ¬é¢ç¨³å¥')

    # ä¸»è¦é£é™©
    if market['overall_trend_strength'] < 0.4:
        summary['main_risks'].append('å¤§ç›˜è¶‹åŠ¿åå¼±')

    if not sector['is_sector_hot']:
        summary['main_risks'].append('éçƒ­é—¨æ¿å—')

    if len(summary['key_drivers']) > len(summary['main_risks']):
        summary['investment_suggestion'] = 'å¯è€ƒè™‘é€¢ä½å…³æ³¨'
    else:
        summary['investment_suggestion'] = 'å»ºè®®è°¨æ…æ“ä½œ'

    return summary


# ==================== å¢å¼ºå¯è§†åŒ–å‡½æ•° ====================
def plot_comprehensive_prediction(
        historical_df,
        prediction_df,
        future_dates,
        stock_code,
        stock_name,
        output_dir,
        enhancement_info=None
):
    """
    ç»˜åˆ¶ç»¼åˆé¢„æµ‹å›¾è¡¨ - åŒ…å«æ›´å¤šå¸‚åœºåˆ†æä¿¡æ¯
    """
    ensure_output_directory(output_dir)

    # è®¾ç½®é…è‰²
    colors = {
        'historical': '#1f77b4',
        'prediction': '#ff7f0e',
        'enhanced': '#2ca02c',
        'background': '#f8f9fa',
        'grid': '#e9ecef',
        'positive': '#2ecc71',
        'negative': '#e74c3c',
        'neutral': '#95a5a6'
    }

    # åˆ›å»ºç»¼åˆå›¾è¡¨
    fig = plt.figure(figsize=(18, 14))
    gs = plt.GridSpec(4, 3, figure=fig, height_ratios=[2, 1, 1, 1])

    # 1. ä¸»ä»·æ ¼å›¾è¡¨
    ax1 = fig.add_subplot(gs[0, :])
    ax1.set_facecolor(colors['background'])

    # 2. æˆäº¤é‡å›¾è¡¨
    ax2 = fig.add_subplot(gs[1, :])
    ax2.set_facecolor(colors['background'])

    # 3. å¸‚åœºåˆ†æå›¾è¡¨
    ax3 = fig.add_subplot(gs[2, 0])
    ax3.set_facecolor(colors['background'])

    ax4 = fig.add_subplot(gs[2, 1])
    ax4.set_facecolor(colors['background'])

    ax5 = fig.add_subplot(gs[2, 2])
    ax5.set_facecolor(colors['background'])

    # 4. å› ç´ åˆ†æå›¾è¡¨
    ax6 = fig.add_subplot(gs[3, :])
    ax6.set_facecolor(colors['background'])

    # è®¾ç½®èƒŒæ™¯è‰²
    fig.patch.set_facecolor('white')

    # 1. ä»·æ ¼å›¾è¡¨
    historical_prices = historical_df.set_index('timestamps')['close']
    prediction_prices = prediction_df.set_index(pd.DatetimeIndex(future_dates))['close']

    # è·å–å½“å‰æœ€æ–°ä»·æ ¼
    current_price = historical_prices.iloc[-1]

    # æ™ºèƒ½Yè½´èŒƒå›´è®¡ç®—
    all_prices = pd.concat([historical_prices, prediction_prices])
    data_min = all_prices.min()
    data_max = all_prices.max()

    price_range = data_max - data_min
    y_margin = price_range * 0.15

    y_min = max(0, data_min - y_margin)
    y_max = data_max + y_margin

    # è®¾ç½®Yè½´åˆ»åº¦
    y_interval = calculate_optimal_interval(y_min, y_max)
    y_ticks = np.arange(round(y_min / y_interval) * y_interval,
                        round(y_max / y_interval) * y_interval + y_interval,
                        y_interval)

    # ç»˜åˆ¶å†å²ä»·æ ¼
    ax1.plot(historical_prices.index, historical_prices.values,
             color=colors['historical'], linewidth=2, label='å†å²ä»·æ ¼')

    # ç»˜åˆ¶é¢„æµ‹ä»·æ ¼
    if len(prediction_prices) > 0:
        # è¿æ¥ç‚¹
        last_hist_date = historical_prices.index[-1]
        last_hist_price = historical_prices.iloc[-1]
        first_pred_date = prediction_prices.index[0]

        # ç»˜åˆ¶è¿æ¥çº¿
        ax1.plot([last_hist_date, first_pred_date],
                 [last_hist_price, prediction_prices.iloc[0]],
                 color=colors['prediction'], linewidth=2.5, linestyle='-')

        # ç»˜åˆ¶é¢„æµ‹çº¿
        ax1.plot(prediction_prices.index, prediction_prices.values,
                 color=colors['prediction'], linewidth=2.5, label='åŸºç¡€é¢„æµ‹')

        # ç»˜åˆ¶å¢å¼ºé¢„æµ‹çº¿
        if enhancement_info and 'enhanced_prediction' in enhancement_info:
            enhanced_prices = enhancement_info['enhanced_prediction'].set_index(pd.DatetimeIndex(future_dates))['close']
            ax1.plot(enhanced_prices.index, enhanced_prices.values,
                     color=colors['enhanced'], linewidth=2.5, linestyle='--', label='å¢å¼ºé¢„æµ‹')

        # æ ‡è®°é¢„æµ‹èµ·ç‚¹
        ax1.axvline(x=last_hist_date, color='red', linestyle='--', alpha=0.7, linewidth=1)
        ax1.annotate('é¢„æµ‹èµ·ç‚¹', xy=(last_hist_date, last_hist_price),
                     xytext=(10, 10), textcoords='offset points',
                     fontsize=10, fontweight='bold',
                     bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))

    # è®¾ç½®Yè½´èŒƒå›´å’Œåˆ»åº¦
    ax1.set_ylim(y_min, y_max)
    ax1.set_yticks(y_ticks)

    ax1.set_ylabel('æ”¶ç›˜ä»· (å…ƒ)', fontsize=12, fontweight='bold')
    ax1.legend(loc='upper left', fontsize=11)
    ax1.grid(True, color=colors['grid'], alpha=0.7)

    title = f'{stock_name}({stock_code}) - ç»¼åˆå› ç´ ä»·æ ¼é¢„æµ‹\nå½“å‰ä»·: {current_price:.2f}å…ƒ | å¢å¼ºå› å­: {enhancement_info["adjustment_factor"]:.3f}' if enhancement_info else f'{stock_name}({stock_code}) - ä»·æ ¼é¢„æµ‹\nå½“å‰ä»·: {current_price:.2f}å…ƒ'
    ax1.set_title(title, fontsize=14, fontweight='bold', pad=20)

    # è®¾ç½®xè½´æ ¼å¼
    ax1.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)

    # 2. æˆäº¤é‡å›¾è¡¨
    historical_volume = historical_df.set_index('timestamps')['volume']
    prediction_volume = prediction_df.set_index(pd.DatetimeIndex(future_dates))['volume']

    # è®¡ç®—ç›¸å¯¹æˆäº¤é‡ï¼ˆæ ‡å‡†åŒ–ï¼‰
    hist_volume_norm = historical_volume / historical_volume.max()
    if len(prediction_volume) > 0:
        pred_volume_norm = prediction_volume / historical_volume.max()

    # ç»˜åˆ¶å†å²æˆäº¤é‡
    ax2.bar(historical_volume.index, hist_volume_norm.values,
            alpha=0.6, color=colors['historical'], label='å†å²æˆäº¤é‡')

    # ç»˜åˆ¶é¢„æµ‹æˆäº¤é‡
    if len(prediction_volume) > 0:
        ax2.bar(prediction_volume.index, pred_volume_norm.values,
                alpha=0.6, color=colors['prediction'], label='é¢„æµ‹æˆäº¤é‡')

    ax2.set_ylabel('ç›¸å¯¹æˆäº¤é‡', fontsize=12, fontweight='bold')
    ax2.legend(loc='upper left', fontsize=11)
    ax2.grid(True, color=colors['grid'], alpha=0.7)
    ax2.set_ylim(0, 1.2)

    # è®¾ç½®xè½´æ ¼å¼
    ax2.xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m-%d'))
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)

    # 3. å¸‚åœºåˆ†æå­å›¾
    if enhancement_info:
        # å› ç´ æƒé‡é¥¼å›¾
        factors = ['å¤§ç›˜è¶‹åŠ¿', 'æ¿å—å…±æŒ¯', 'å®è§‚ç¯å¢ƒ', 'ç¾å›½é™æ¯', 'åŸºæœ¬é¢']
        weights = [25, 25, 20, 10, 20]
        colors_pie = [colors['historical'], colors['prediction'], colors['enhanced'], '#f39c12', '#9b59b6']

        ax3.pie(weights, labels=factors, autopct='%1.0f%%', colors=colors_pie, startangle=90)
        ax3.set_title('å› ç´ æƒé‡åˆ†é…', fontweight='bold', fontsize=11)

        # å› ç´ è¯„åˆ†æŸ±çŠ¶å›¾
        scores = [
            enhancement_info['market_analysis']['overall_trend_strength'],
            enhancement_info['sector_analysis']['resonance_score'],
            enhancement_info['macro_analysis']['overall_macro_score'],
            0.7 if enhancement_info['macro_analysis']['us_rate_cycle']['trend'] == 'é™æ¯å‘¨æœŸ' else 0.3,
            enhancement_info['fundamental_analysis']['fundamental_score']
        ]

        x_pos = np.arange(len(factors))
        bars = ax4.bar(x_pos, scores, color=colors_pie, alpha=0.7)
        ax4.set_xticks(x_pos)
        ax4.set_xticklabels(factors, rotation=45, fontsize=9)
        ax4.set_ylim(0, 1)
        ax4.set_ylabel('è¯„åˆ†', fontsize=10)
        ax4.set_title('å„å› ç´ å½“å‰è¯„åˆ†', fontweight='bold', fontsize=11)
        ax4.grid(True, alpha=0.3)

        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                     f'{height:.2f}', ha='center', va='bottom', fontsize=8)

        # å¸‚åœºçŠ¶æ€æ€»ç»“
        market_status = enhancement_info['market_analysis']['market_status']
        sector_status = "çƒ­é—¨" if enhancement_info['sector_analysis']['is_sector_hot'] else "ä¸€èˆ¬"
        macro_status = "æœ‰åˆ©" if enhancement_info['macro_analysis']['overall_macro_score'] > 0.6 else "ä¸åˆ©"

        summary_text = f"""å¸‚åœºçŠ¶æ€æ€»ç»“:

å¤§ç›˜è¶‹åŠ¿: {market_status}
æ¿å—çƒ­åº¦: {sector_status}
å®è§‚ç¯å¢ƒ: {macro_status}
ç¾å›½åˆ©ç‡: {enhancement_info['macro_analysis']['us_rate_cycle']['trend']}
ç»¼åˆè¯„åˆ†: {enhancement_info['adjustment_factor']:.3f}

æŠ•èµ„å»ºè®®: {enhancement_info['fundamental_analysis']['investment_rating']}"""

        ax5.text(0.1, 0.9, summary_text, transform=ax5.transAxes, fontsize=10,
                 verticalalignment='top', linespacing=1.5)
        ax5.set_title('å¸‚åœºçŠ¶æ€æ€»ç»“', fontweight='bold', fontsize=11)
        ax5.set_xticks([])
        ax5.set_yticks([])
        ax5.spines['top'].set_visible(False)
        ax5.spines['right'].set_visible(False)
        ax5.spines['bottom'].set_visible(False)
        ax5.spines['left'].set_visible(False)

        # 4. è¯¦ç»†å› ç´ åˆ†æ
        if 'analysis_summary' in enhancement_info:
            summary = enhancement_info['analysis_summary']
            drivers_text = "\n".join([f"â€¢ {driver}" for driver in summary['key_drivers']]) if summary[
                'key_drivers'] else "â€¢ æš‚æ— æ˜æ˜¾é©±åŠ¨"
            risks_text = "\n".join([f"â€¢ {risk}" for risk in summary['main_risks']]) if summary[
                'main_risks'] else "â€¢ é£é™©å¯æ§"

            detail_text = f"""å…³é”®é©±åŠ¨å› ç´ :
{drivers_text}

ä¸»è¦é£é™©æç¤º:
{risks_text}

æ€»ä½“æƒ…ç»ª: {summary['overall_sentiment']}
å»ºè®®: {summary['investment_suggestion']}"""

            ax6.text(0.02, 0.95, detail_text, transform=ax6.transAxes, fontsize=9,
                     verticalalignment='top', linespacing=1.3)
            ax6.set_title('è¯¦ç»†å› ç´ åˆ†æ', fontweight='bold', fontsize=11)
            ax6.set_xticks([])
            ax6.set_yticks([])
            ax6.spines['top'].set_visible(False)
            ax6.spines['right'].set_visible(False)
            ax6.spines['bottom'].set_visible(False)
            ax6.spines['left'].set_visible(False)

    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    chart_filename = os.path.join(output_dir, f'{stock_code}_comprehensive_prediction.png')
    plt.savefig(chart_filename, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"ğŸ“Š ç»¼åˆé¢„æµ‹å›¾è¡¨å·²ä¿å­˜: {chart_filename}")

    plt.show()

    return historical_prices, prediction_prices


# ==================== ä¸»é¢„æµ‹å‡½æ•° ====================
def run_comprehensive_kronos_prediction(stock_code, stock_name, data_dir, pred_days, output_dir, history_years=1):
    """
    è¿è¡Œç»¼åˆç‰ˆKronosæ¨¡å‹é¢„æµ‹æµç¨‹
    """
    print(f"\nğŸ¯ å¼€å§‹ {stock_name}({stock_code}) ç»¼åˆç‰ˆKronosæ¨¡å‹ä»·æ ¼é¢„æµ‹")
    print("=" * 60)

    # åˆå§‹åŒ–å¢å¼ºç‰ˆå¸‚åœºåˆ†æå™¨
    market_analyzer = EnhancedMarketFactorAnalyzer()

    try:
        # 1. è·å–æ•°æ®
        print("\næ­¥éª¤1: è·å–è‚¡ç¥¨æ•°æ®...")
        success, csv_file_path = get_stock_data(stock_code, data_dir)
        if not success:
            print("âŒ æ— æ³•è·å–è‚¡ç¥¨æ•°æ®ï¼Œé¢„æµ‹ç»ˆæ­¢")
            return

        # 2. åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
        print("\næ­¥éª¤2: åŠ è½½Kronosæ¨¡å‹å’Œåˆ†è¯å™¨...")
        try:
            tokenizer = KronosTokenizer.from_pretrained("NeoQuasar/Kronos-Tokenizer-base")
            model = Kronos.from_pretrained("NeoQuasar/Kronos-base")
            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ - ä½¿ç”¨Kronos-baseæ¨¡å‹")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("âš ï¸ é¢„æµ‹åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æ¨¡å‹å®‰è£…")
            return

        # 3. å®ä¾‹åŒ–é¢„æµ‹å™¨
        print("æ­¥éª¤3: åˆå§‹åŒ–é¢„æµ‹å™¨...")
        predictor = KronosPredictor(model, tokenizer, device="cuda:0", max_context=512)
        print("âœ… é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")

        # 4. å‡†å¤‡æ•°æ®
        print("æ­¥éª¤4: å‡†å¤‡è‚¡ç¥¨æ•°æ®...")
        df = prepare_stock_data(csv_file_path, stock_code, history_years)

        # 5. è®¡ç®—é¢„æµ‹å‚æ•°
        print("æ­¥éª¤5: è®¡ç®—é¢„æµ‹å‚æ•°...")
        lookback, pred_len = calculate_prediction_parameters(df, target_days=pred_days)

        if pred_len <= 0:
            print("âŒ æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
            return

        print(f"âœ… æœ€ç»ˆå‚æ•° - å›çœ‹æœŸ: {lookback}, é¢„æµ‹æœŸ: {pred_len}")

        # 6. å‡†å¤‡è¾“å…¥æ•°æ®
        print("æ­¥éª¤6: å‡†å¤‡è¾“å…¥æ•°æ®...")
        x_df = df.loc[-lookback:, ['open', 'high', 'low', 'close', 'volume', 'amount']].reset_index(drop=True)
        x_timestamp = df.loc[-lookback:, 'timestamps'].reset_index(drop=True)

        # ç”Ÿæˆæœªæ¥æ—¥æœŸ
        last_historical_date = df['timestamps'].iloc[-1]
        future_dates = generate_future_dates(last_historical_date, pred_len)

        print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {x_df.shape}")
        print(f"å†å²æ•°æ®æ—¶é—´èŒƒå›´: {x_timestamp.iloc[0]} åˆ° {x_timestamp.iloc[-1]}")
        print(f"é¢„æµ‹æ—¶é—´èŒƒå›´: {future_dates[0]} åˆ° {future_dates[-1]}")

        # 7. æ‰§è¡ŒåŸºç¡€é¢„æµ‹
        print("æ­¥éª¤7: æ‰§è¡ŒåŸºç¡€ä»·æ ¼é¢„æµ‹...")
        pred_df = predictor.predict(
            df=x_df,
            x_timestamp=x_timestamp,
            y_timestamp=pd.Series(future_dates),
            pred_len=pred_len,
            T=1.0,
            top_p=0.9,
            sample_count=1,
            verbose=True
        )

        print("âœ… åŸºç¡€é¢„æµ‹å®Œæˆ")
        print("é¢„æµ‹æ•°æ®å‰5è¡Œ:")
        print(pred_df.head())

        # 8. ä½¿ç”¨å¤šç»´åº¦å¸‚åœºå› ç´ å¢å¼ºé¢„æµ‹
        print("æ­¥éª¤8: åº”ç”¨å¤šç»´åº¦å¸‚åœºå› ç´ å¢å¼ºé¢„æµ‹...")
        enhanced_pred_df, enhancement_info = enhance_prediction_with_market_factors(
            df.loc[-lookback:].reset_index(drop=True),
            pred_df,
            stock_code,
            market_analyzer
        )

        # å°†å¢å¼ºé¢„æµ‹ç»“æœæ·»åŠ åˆ°ä¿¡æ¯ä¸­
        enhancement_info['enhanced_prediction'] = enhanced_pred_df

        # 9. åˆ›å»ºç»¼åˆå¸‚åœºåˆ†ææŠ¥å‘Š
        market_report = create_comprehensive_market_report(enhancement_info, output_dir, stock_code)

        # 10. å¯è§†åŒ–ç»“æœ
        print("æ­¥éª¤9: ç”Ÿæˆç»¼åˆç‰ˆå¯è§†åŒ–å›¾è¡¨...")
        historical_df = df.loc[-lookback:].reset_index(drop=True)
        hist_prices, base_pred_prices = plot_comprehensive_prediction(
            historical_df, pred_df, future_dates, stock_code, stock_name, output_dir, enhancement_info
        )

        # 11. ç”Ÿæˆç»¼åˆé¢„æµ‹æŠ¥å‘Š
        print("æ­¥éª¤10: ç”Ÿæˆç»¼åˆé¢„æµ‹æŠ¥å‘Š...")
        if len(enhanced_pred_df) > 0:
            current_price = hist_prices.iloc[-1]
            base_predicted_price = base_pred_prices.iloc[-1] if len(base_pred_prices) > 0 else current_price
            enhanced_predicted_price = enhanced_pred_df.set_index(pd.DatetimeIndex(future_dates))['close'].iloc[-1]

            base_change_pct = (base_predicted_price / current_price - 1) * 100
            enhanced_change_pct = (enhanced_predicted_price / current_price - 1) * 100

            print(f"\nğŸ“ˆ ç»¼åˆç‰ˆKronosæ¨¡å‹é¢„æµ‹æŠ¥å‘Š")
            print("=" * 70)
            print(f"è‚¡ç¥¨: {stock_name}({stock_code})")
            print(f"å½“å‰ä»·æ ¼: {current_price:.2f} å…ƒ")
            print(f"åŸºç¡€é¢„æµ‹ä»·æ ¼: {base_predicted_price:.2f} å…ƒ ({base_change_pct:+.2f}%)")
            print(f"å¢å¼ºé¢„æµ‹ä»·æ ¼: {enhanced_predicted_price:.2f} å…ƒ ({enhanced_change_pct:+.2f}%)")
            print(f"å¸‚åœºå› ç´ è°ƒæ•´å› å­: {enhancement_info['adjustment_factor']:.4f}")
            print(f"å¤§ç›˜çŠ¶æ€: {enhancement_info['market_analysis']['market_status']}")
            print(
                f"æ¿å—å…±æŒ¯: {enhancement_info['sector_analysis']['main_sector']['sector']} (åˆ†æ•°: {enhancement_info['sector_analysis']['resonance_score']:.2f})")
            print(f"å®è§‚ç¯å¢ƒ: ç¾å›½{enhancement_info['macro_analysis']['us_rate_cycle']['trend']}")
            print(f"å…¬å¸è¯„çº§: {enhancement_info['fundamental_analysis']['investment_rating']}")
            print(f"é¢„æµ‹æœŸé—´: {pred_len} ä¸ªäº¤æ˜“æ—¥")

            # è¾“å‡ºå…³é”®å› ç´ 
            print(f"\nğŸ”‘ å…³é”®å½±å“å› ç´ :")
            for driver in enhancement_info['analysis_summary']['key_drivers']:
                print(f"  âœ… {driver}")
            for risk in enhancement_info['analysis_summary']['main_risks']:
                print(f"  âš ï¸  {risk}")
            print(f"  ğŸ’¡ æŠ•èµ„å»ºè®®: {enhancement_info['analysis_summary']['investment_suggestion']}")

            # ä¿å­˜è¯¦ç»†é¢„æµ‹æ•°æ®
            prediction_details = pd.DataFrame({
                'æ—¥æœŸ': future_dates,
                'åŸºç¡€é¢„æµ‹æ”¶ç›˜ä»·': base_pred_prices.values if len(base_pred_prices) > 0 else [current_price] * len(
                    future_dates),
                'å¢å¼ºé¢„æµ‹æ”¶ç›˜ä»·': enhanced_pred_df['close'].values,
                'é¢„æµ‹æˆäº¤é‡': enhanced_pred_df['volume'].values
            })

            prediction_file = os.path.join(output_dir, f'{stock_code}_comprehensive_predictions.csv')
            prediction_details.to_csv(prediction_file, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ è¯¦ç»†é¢„æµ‹æ•°æ®å·²ä¿å­˜: {prediction_file}")

        print(f"\nğŸ‰ {stock_name}({stock_code}) ç»¼åˆç‰ˆKronosæ¨¡å‹é¢„æµ‹å®Œæˆ!")

    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


# ==================== ä¸»å‡½æ•° ====================
def main():
    """
    ä¸»å‡½æ•°ï¼šç»¼åˆç‰ˆKronosæ¨¡å‹è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ
    """
    # ==================== é…ç½®å‚æ•° ====================
    STOCK_CONFIG = {
        "stock_code": "603288",
        "stock_name": "æµ·å¤©å‘³ä¸š",
        "data_dir": r"D:\lianghuajiaoyi\Kronos\examples\data",
        "pred_days": 60,
        "output_dir": r"D:\lianghuajiaoyi\Kronos\examples\yuce",
        "history_years": 1
    }

    print("ğŸ¤– ç»¼åˆç‰ˆKronosæ¨¡å‹è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ")
    print("=" * 50)
    print("ğŸ“Š æ–°å¢åŠŸèƒ½: å¤šç»´åº¦å¸‚åœºå› ç´ åˆ†æ")
    print("ğŸ¯ åŒ…å«: å¤§ç›˜è¶‹åŠ¿ + æ¿å—å…±æŒ¯ + å®è§‚æ”¿ç­– + å…¬å¸åŸºæœ¬é¢")
    print("ğŸš€ ä½¿ç”¨æ¨¡å‹: Kronos-base (æ›´é€‚åˆ3070Tiæ˜¾å¡)")
    print(f"å½“å‰é¢„æµ‹è‚¡ç¥¨: {STOCK_CONFIG['stock_name']}({STOCK_CONFIG['stock_code']})")
    print(f"é¢„æµ‹å¤©æ•°: {STOCK_CONFIG['pred_days']} å¤©")
    print(f"è¾“å‡ºç›®å½•: {STOCK_CONFIG['output_dir']}")
    print()

    # è¿è¡Œç»¼åˆç‰ˆKronosæ¨¡å‹é¢„æµ‹æµç¨‹
    run_comprehensive_kronos_prediction(**STOCK_CONFIG)

    print(f"\nğŸ’¡ æç¤ºï¼šç»¼åˆç‰ˆæ¨¡å‹å·²æ•´åˆå¤šç»´åº¦å¸‚åœºç¯å¢ƒåˆ†æå› å­")


if __name__ == "__main__":
    main()
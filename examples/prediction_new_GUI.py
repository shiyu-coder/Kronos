import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import sys
import os
from datetime import datetime, timedelta
import warnings
import requests
import json
import time
import random
import akshare as ak
from typing import Dict, List, Tuple, Optional
import tkinter as tk
from tkinter import ttk, messagebox, filedialog
import threading
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import matplotlib.dates as mdates
import matplotlib.ticker as ticker

warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„ä»¥ä¾¿å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.append("../")
try:
    from model import Kronos, KronosTokenizer, KronosPredictor
except ImportError:
    print("âš ï¸ æ— æ³•å¯¼å…¥Kronosæ¨¡å‹ï¼Œé¢„æµ‹åŠŸèƒ½å°†ä¸å¯ç”¨")

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·


class StockPredictorGUI:
    """è‚¡ç¥¨é¢„æµ‹å›¾å½¢ç•Œé¢"""

    def __init__(self, root):
        self.root = root
        self.root.title("Kronosè‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ")
        self.root.geometry("800x600")
        self.root.configure(bg='#f0f0f0')

        # åˆå§‹åŒ–å¸‚åœºåˆ†æå™¨
        self.market_analyzer = EnhancedMarketFactorAnalyzer()

        # åˆ›å»ºç•Œé¢
        self.create_widgets()

        # é»˜è®¤é…ç½®
        self.default_config = {
            "stock_code": "600580",
            "stock_name": "å§é¾™ç”µé©±",
            "data_dir": r"D:\lianghuajiaoyi\Kronos\examples\data",
            "output_dir": r"D:\lianghuajiaoyi\Kronos\examples\yuce",
            "pred_days": 60,
            "history_years": 1
        }

    def create_widgets(self):
        """åˆ›å»ºç•Œé¢ç»„ä»¶"""
        # ä¸»æ ‡é¢˜
        title_label = tk.Label(
            self.root,
            text="ğŸ¤– Kronosè‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ",
            font=("Arial", 16, "bold"),
            bg='#f0f0f0',
            fg='#2c3e50'
        )
        title_label.pack(pady=10)

        # è¯´æ˜æ ‡ç­¾
        desc_label = tk.Label(
            self.root,
            text="åŸºäºKronosæ¨¡å‹çš„å¤šç»´åº¦è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ",
            font=("Arial", 10),
            bg='#f0f0f0',
            fg='#7f8c8d'
        )
        desc_label.pack(pady=5)

        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = tk.Frame(self.root, bg='#f0f0f0')
        main_frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=10)

        # è¾“å…¥æ¡†æ¶
        input_frame = tk.LabelFrame(main_frame, text="è‚¡ç¥¨å‚æ•°è®¾ç½®", font=("Arial", 11, "bold"),
                                    bg='#f0f0f0', fg='#2c3e50')
        input_frame.pack(fill=tk.X, pady=10)

        # è‚¡ç¥¨ä»£ç è¾“å…¥
        tk.Label(input_frame, text="è‚¡ç¥¨ä»£ç :", bg='#f0f0f0', font=("Arial", 10)).grid(row=0, column=0, sticky=tk.W,
                                                                                       padx=5, pady=5)
        self.stock_code_var = tk.StringVar(value="600580")
        stock_code_entry = tk.Entry(input_frame, textvariable=self.stock_code_var, font=("Arial", 10), width=15)
        stock_code_entry.grid(row=0, column=1, padx=5, pady=5)

        # è‚¡ç¥¨åç§°è¾“å…¥
        tk.Label(input_frame, text="è‚¡ç¥¨åç§°:", bg='#f0f0f0', font=("Arial", 10)).grid(row=0, column=2, sticky=tk.W,
                                                                                       padx=5, pady=5)
        self.stock_name_var = tk.StringVar(value="å§é¾™ç”µé©±")
        stock_name_entry = tk.Entry(input_frame, textvariable=self.stock_name_var, font=("Arial", 10), width=15)
        stock_name_entry.grid(row=0, column=3, padx=5, pady=5)

        # é¢„æµ‹å¤©æ•°
        tk.Label(input_frame, text="é¢„æµ‹å¤©æ•°:", bg='#f0f0f0', font=("Arial", 10)).grid(row=1, column=0, sticky=tk.W,
                                                                                       padx=5, pady=5)
        self.pred_days_var = tk.StringVar(value="60")
        pred_days_entry = tk.Entry(input_frame, textvariable=self.pred_days_var, font=("Arial", 10), width=15)
        pred_days_entry.grid(row=1, column=1, padx=5, pady=5)

        # å†å²æ•°æ®å¹´é™
        tk.Label(input_frame, text="å†å²å¹´é™:", bg='#f0f0f0', font=("Arial", 10)).grid(row=1, column=2, sticky=tk.W,
                                                                                       padx=5, pady=5)
        self.history_years_var = tk.StringVar(value="1")
        history_years_entry = tk.Entry(input_frame, textvariable=self.history_years_var, font=("Arial", 10), width=15)
        history_years_entry.grid(row=1, column=3, padx=5, pady=5)

        # ç›®å½•è®¾ç½®æ¡†æ¶
        dir_frame = tk.LabelFrame(main_frame, text="ç›®å½•è®¾ç½®", font=("Arial", 11, "bold"),
                                  bg='#f0f0f0', fg='#2c3e50')
        dir_frame.pack(fill=tk.X, pady=10)

        # æ•°æ®ç›®å½•
        tk.Label(dir_frame, text="æ•°æ®ç›®å½•:", bg='#f0f0f0', font=("Arial", 10)).grid(row=0, column=0, sticky=tk.W,
                                                                                     padx=5, pady=5)
        self.data_dir_var = tk.StringVar(value=r"D:\lianghuajiaoyi\Kronos\examples\data")
        data_dir_entry = tk.Entry(dir_frame, textvariable=self.data_dir_var, font=("Arial", 10), width=40)
        data_dir_entry.grid(row=0, column=1, padx=5, pady=5)
        tk.Button(dir_frame, text="æµè§ˆ", command=self.browse_data_dir, font=("Arial", 9)).grid(row=0, column=2, padx=5,
                                                                                                pady=5)

        # è¾“å‡ºç›®å½•
        tk.Label(dir_frame, text="è¾“å‡ºç›®å½•:", bg='#f0f0f0', font=("Arial", 10)).grid(row=1, column=0, sticky=tk.W,
                                                                                     padx=5, pady=5)
        self.output_dir_var = tk.StringVar(value=r"D:\lianghuajiaoyi\Kronos\examples\yuce")
        output_dir_entry = tk.Entry(dir_frame, textvariable=self.output_dir_var, font=("Arial", 10), width=40)
        output_dir_entry.grid(row=1, column=1, padx=5, pady=5)
        tk.Button(dir_frame, text="æµè§ˆ", command=self.browse_output_dir, font=("Arial", 9)).grid(row=1, column=2,
                                                                                                  padx=5, pady=5)

        # åŠŸèƒ½æŒ‰é’®æ¡†æ¶
        button_frame = tk.Frame(main_frame, bg='#f0f0f0')
        button_frame.pack(pady=20)

        # é¢„æµ‹æŒ‰é’®
        self.predict_button = tk.Button(
            button_frame,
            text="ğŸš€ å¼€å§‹é¢„æµ‹",
            command=self.start_prediction,
            font=("Arial", 12, "bold"),
            bg='#3498db',
            fg='white',
            width=15,
            height=2
        )
        self.predict_button.pack(side=tk.LEFT, padx=10)

        # é‡ç½®æŒ‰é’®
        reset_button = tk.Button(
            button_frame,
            text="ğŸ”„ é‡ç½®",
            command=self.reset_fields,
            font=("Arial", 10),
            bg='#95a5a6',
            fg='white',
            width=10,
            height=2
        )
        reset_button.pack(side=tk.LEFT, padx=10)

        # é€€å‡ºæŒ‰é’®
        exit_button = tk.Button(
            button_frame,
            text="âŒ é€€å‡º",
            command=self.root.quit,
            font=("Arial", 10),
            bg='#e74c3c',
            fg='white',
            width=10,
            height=2
        )
        exit_button.pack(side=tk.LEFT, padx=10)

        # è¿›åº¦æ˜¾ç¤º
        self.progress_frame = tk.LabelFrame(main_frame, text="é¢„æµ‹è¿›åº¦", font=("Arial", 11, "bold"),
                                            bg='#f0f0f0', fg='#2c3e50')
        self.progress_frame.pack(fill=tk.X, pady=10)

        self.progress_var = tk.StringVar(value="ç­‰å¾…å¼€å§‹é¢„æµ‹...")
        progress_label = tk.Label(self.progress_frame, textvariable=self.progress_var, bg='#f0f0f0',
                                  font=("Arial", 10), wraplength=700, justify=tk.LEFT)
        progress_label.pack(padx=10, pady=10, fill=tk.X)

        # è¿›åº¦æ¡
        self.progress_bar = ttk.Progressbar(self.progress_frame, mode='indeterminate')
        self.progress_bar.pack(fill=tk.X, padx=10, pady=5)

        # ç»“æœå±•ç¤ºåŒºåŸŸ
        self.result_frame = tk.LabelFrame(main_frame, text="é¢„æµ‹ç»“æœ", font=("Arial", 11, "bold"),
                                          bg='#f0f0f0', fg='#2c3e50')
        self.result_frame.pack(fill=tk.BOTH, expand=True, pady=10)

        self.result_text = tk.Text(self.result_frame, height=8, font=("Arial", 9), wrap=tk.WORD)
        scrollbar = tk.Scrollbar(self.result_frame, command=self.result_text.yview)
        self.result_text.configure(yscrollcommand=scrollbar.set)
        self.result_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y, pady=5)

    def browse_data_dir(self):
        """æµè§ˆæ•°æ®ç›®å½•"""
        directory = filedialog.askdirectory()
        if directory:
            self.data_dir_var.set(directory)

    def browse_output_dir(self):
        """æµè§ˆè¾“å‡ºç›®å½•"""
        directory = filedialog.askdirectory()
        if directory:
            self.output_dir_var.set(directory)

    def reset_fields(self):
        """é‡ç½®è¾“å…¥å­—æ®µ"""
        self.stock_code_var.set("600580")
        self.stock_name_var.set("å§é¾™ç”µé©±")
        self.pred_days_var.set("60")
        self.history_years_var.set("1")
        self.data_dir_var.set(r"D:\lianghuajiaoyi\Kronos\examples\data")
        self.output_dir_var.set(r"D:\lianghuajiaoyi\Kronos\examples\yuce")
        self.result_text.delete(1.0, tk.END)
        self.progress_var.set("ç­‰å¾…å¼€å§‹é¢„æµ‹...")

    def start_prediction(self):
        """å¼€å§‹é¢„æµ‹"""
        # éªŒè¯è¾“å…¥
        if not self.validate_inputs():
            return

        # ç¦ç”¨é¢„æµ‹æŒ‰é’®
        self.predict_button.config(state=tk.DISABLED)

        # æ¸…ç©ºç»“æœåŒºåŸŸ
        self.result_text.delete(1.0, tk.END)

        # å¼€å§‹è¿›åº¦æ¡
        self.progress_bar.start()

        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œé¢„æµ‹
        prediction_thread = threading.Thread(target=self.run_prediction)
        prediction_thread.daemon = True
        prediction_thread.start()

    def validate_inputs(self):
        """éªŒè¯è¾“å…¥å‚æ•°"""
        try:
            stock_code = self.stock_code_var.get().strip()
            stock_name = self.stock_name_var.get().strip()
            pred_days = int(self.pred_days_var.get())
            history_years = int(self.history_years_var.get())

            if not stock_code:
                messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ")
                return False

            if not stock_name:
                messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥è‚¡ç¥¨åç§°")
                return False

            if pred_days <= 0 or pred_days > 365:
                messagebox.showerror("é”™è¯¯", "é¢„æµ‹å¤©æ•°åº”åœ¨1-365å¤©ä¹‹é—´")
                return False

            if history_years <= 0 or history_years > 10:
                messagebox.showerror("é”™è¯¯", "å†å²å¹´é™åº”åœ¨1-10å¹´ä¹‹é—´")
                return False

            return True

        except ValueError:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            return False

    def run_prediction(self):
        """è¿è¡Œé¢„æµ‹æµç¨‹"""
        try:
            # è·å–è¾“å…¥å‚æ•°
            stock_code = self.stock_code_var.get().strip()
            stock_name = self.stock_name_var.get().strip()
            pred_days = int(self.pred_days_var.get())
            history_years = int(self.history_years_var.get())
            data_dir = self.data_dir_var.get()
            output_dir = self.output_dir_var.get()

            # æ›´æ–°è¿›åº¦
            self.update_progress("ğŸ¯ å¼€å§‹è‚¡ç¥¨é¢„æµ‹æµç¨‹...")

            # è¿è¡Œé¢„æµ‹
            success, result = run_comprehensive_prediction_gui(
                stock_code, stock_name, data_dir, pred_days, output_dir, history_years,
                progress_callback=self.update_progress,
                result_callback=self.update_result
            )

            if success:
                self.update_progress("âœ… é¢„æµ‹å®Œæˆï¼")
                messagebox.showinfo("å®Œæˆ", f"{stock_name}({stock_code})é¢„æµ‹å®Œæˆï¼\nå›¾è¡¨å·²ä¿å­˜åˆ°è¾“å‡ºç›®å½•ã€‚")
            else:
                self.update_progress("âŒ é¢„æµ‹å¤±è´¥")
                messagebox.showerror("é”™è¯¯", f"é¢„æµ‹å¤±è´¥: {result}")

        except Exception as e:
            self.update_progress(f"âŒ é¢„æµ‹è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}")
            messagebox.showerror("é”™è¯¯", f"é¢„æµ‹è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}")
        finally:
            # é‡æ–°å¯ç”¨é¢„æµ‹æŒ‰é’®
            self.root.after(0, lambda: self.predict_button.config(state=tk.NORMAL))
            # åœæ­¢è¿›åº¦æ¡
            self.root.after(0, self.progress_bar.stop)

    def update_progress(self, message):
        """æ›´æ–°è¿›åº¦ä¿¡æ¯"""
        self.root.after(0, lambda: self.progress_var.set(message))
        print(message)  # åŒæ—¶åœ¨æ§åˆ¶å°è¾“å‡º

    def update_result(self, message):
        """æ›´æ–°ç»“æœä¿¡æ¯"""
        self.root.after(0, lambda: self.result_text.insert(tk.END, message + "\n"))
        self.root.after(0, lambda: self.result_text.see(tk.END))


# ==================== åŸºç¡€æ•°æ®è·å–å‡½æ•° ====================
def ensure_output_directory(output_dir):
    """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"âœ… åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    return output_dir


def fetch_real_stock_data(stock_code, period="daily", adjust="qfq"):
    """
    ä½¿ç”¨AKShareè·å–çœŸå®è‚¡ç¥¨æ•°æ®
    """
    try:
        print(f"ğŸ“¡ æ­£åœ¨é€šè¿‡AKShareè·å– {stock_code} çš„çœŸå®è‚¡ç¥¨æ•°æ®...")

        # è·å–è‚¡ç¥¨æ•°æ®
        df = ak.stock_zh_a_hist(symbol=stock_code, period=period, adjust=adjust)

        if df is None or df.empty:
            print(f"âŒ æœªè·å–åˆ° {stock_code} çš„æ•°æ®")
            return None

        # é‡å‘½ååˆ—ä»¥ç»Ÿä¸€æ ¼å¼
        column_mapping = {
            'æ—¥æœŸ': 'timestamps',
            'å¼€ç›˜': 'open',
            'æ”¶ç›˜': 'close',
            'æœ€é«˜': 'high',
            'æœ€ä½': 'low',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount',
            'æŒ¯å¹…': 'amplitude',
            'æ¶¨è·Œå¹…': 'pct_chg',
            'æ¶¨è·Œé¢': 'change_amount',
            'æ¢æ‰‹ç‡': 'turnover'
        }

        # åªæ˜ å°„å­˜åœ¨çš„åˆ—
        actual_mapping = {k: v for k, v in column_mapping.items() if k in df.columns}
        df = df.rename(columns=actual_mapping)

        # ç¡®ä¿æ—¶é—´æˆ³æ ¼å¼æ­£ç¡®
        df['timestamps'] = pd.to_datetime(df['timestamps'])
        df = df.sort_values('timestamps').reset_index(drop=True)

        # æ·»åŠ è‚¡ç¥¨ä»£ç åˆ—
        df['stock_code'] = stock_code

        print(f"âœ… æˆåŠŸè·å– {len(df)} æ¡çœŸå®æ•°æ®")
        print(f"ğŸ“ˆ æœ€æ–°æ”¶ç›˜ä»·: {df['close'].iloc[-1]:.2f}å…ƒ, æ¶¨è·Œå¹…: {df['pct_chg'].iloc[-1]:.2f}%")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {df['timestamps'].min()} åˆ° {df['timestamps'].max()}")

        return df

    except Exception as e:
        print(f"âŒ AKShareæ•°æ®è·å–å¤±è´¥: {e}")
        return None


def get_stock_data_with_retry_all_history(stock_code="600580", retry_count=2):
    """
    ä¼˜åŒ–çš„æ•°æ®è·å–å‡½æ•° - ä¼˜å…ˆä½¿ç”¨çœŸå®APIæ•°æ®
    """
    print(f"ğŸ”„ å°è¯•è·å–è‚¡ç¥¨ {stock_code} çš„çœŸå®å†å²æ•°æ®...")

    # ä¼˜å…ˆä½¿ç”¨AKShareè·å–çœŸå®æ•°æ®
    df = fetch_real_stock_data(stock_code, "daily", "qfq")

    if df is not None:
        return df
    else:
        print("âš ï¸ çœŸå®æ•°æ®è·å–å¤±è´¥ï¼Œä½¿ç”¨åŸºäºçœŸå®ä»·æ ¼çš„æ¨¡æ‹Ÿæ•°æ®...")
        return create_realistic_fallback_data(stock_code)


def create_realistic_fallback_data(stock_code="600580"):
    """
    åŸºäºçœŸå®ä»·æ ¼çš„å¤‡ç”¨æ•°æ®ç”Ÿæˆå‡½æ•°
    """
    # åŸºäºçœŸå®å¸‚åœºä»·æ ¼çš„å‚è€ƒæ•°æ®
    real_stock_references = {
        '600580': {'name': 'å§é¾™ç”µé©±', 'current_price': 15.20, 'range': (12.0, 20.0)},
        '300207': {'name': 'æ¬£æ—ºè¾¾', 'current_price': 33.79, 'range': (28.0, 38.0)},
        '300418': {'name': 'æ˜†ä»‘ä¸‡ç»´', 'current_price': 48.59, 'range': (40.0, 55.0)},
        '002354': {'name': 'å¤©å¨±æ•°ç§‘', 'current_price': 15.20, 'range': (12.0, 20.0)},
        '000001': {'name': 'å¹³å®‰é“¶è¡Œ', 'current_price': 12.50, 'range': (10.0, 16.0)},
        '600036': {'name': 'æ‹›å•†é“¶è¡Œ', 'current_price': 35.80, 'range': (30.0, 42.0)},
    }

    stock_info = real_stock_references.get(stock_code, {
        'name': 'æœªçŸ¥è‚¡ç¥¨',
        'current_price': 20.0,
        'range': (15.0, 25.0)
    })

    # ç”Ÿæˆæœ€è¿‘1å¹´çš„äº¤æ˜“æ—¥æ•°æ®
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)
    dates = pd.bdate_range(start=start_date, end=end_date, freq='B')

    # ç”ŸæˆåŸºäºçœŸå®ä»·æ ¼çš„ä»·æ ¼åºåˆ—
    np.random.seed(42)
    n_points = len(dates)

    # ä»å½“å‰ä»·æ ¼åå‘ç”Ÿæˆå†å²ä»·æ ¼
    current_price = stock_info['current_price']
    min_price, max_price = stock_info['range']

    # åå‘ç”Ÿæˆä»·æ ¼åºåˆ—
    prices = [current_price]
    for i in range(1, n_points):
        volatility = 0.02
        historical_return = np.random.normal(-0.0002, volatility)

        prev_price = prices[0] * (1 + historical_return)
        prev_price = max(min_price * 0.9, min(max_price * 1.1, prev_price))
        prices.insert(0, prev_price)

    # ç”ŸæˆOHLCæ•°æ®
    stock_data = []
    for i, date in enumerate(dates):
        close_price = prices[i]

        daily_volatility = abs(np.random.normal(0, 0.015))
        open_price = close_price * (1 + np.random.normal(0, 0.005))
        high_price = max(open_price, close_price) * (1 + daily_volatility)
        low_price = min(open_price, close_price) * (1 - daily_volatility)

        high_price = max(open_price, close_price, low_price, high_price)
        low_price = min(open_price, close_price, high_price, low_price)

        volume = int(abs(np.random.normal(1500000, 400000)))
        amount = volume * close_price

        if i > 0:
            pct_chg = ((close_price - prices[i - 1]) / prices[i - 1]) * 100
            change_amount = close_price - prices[i - 1]
        else:
            pct_chg = 0
            change_amount = 0

        stock_data.append({
            'timestamps': date,
            'stock_code': stock_code,
            'open': round(open_price, 2),
            'close': round(close_price, 2),
            'high': round(high_price, 2),
            'low': round(low_price, 2),
            'volume': volume,
            'amount': round(amount, 2),
            'amplitude': round(((high_price - low_price) / open_price) * 100, 2),
            'pct_chg': round(pct_chg, 2),
            'change_amount': round(change_amount, 2),
            'turnover': round(np.random.uniform(3.0, 8.0), 2)
        })

    df = pd.DataFrame(stock_data)
    print(f"âœ… å·²ç”ŸæˆåŸºäºçœŸå®ä»·æ ¼çš„å¤‡ç”¨æ•°æ® {len(df)} æ¡")
    return df


def save_all_history_stock_data(df, stock_code, save_dir):
    """
    ä¿å­˜è‚¡ç¥¨æ•°æ®åˆ°æŒ‡å®šç›®å½•
    """
    if df is not None and not df.empty:
        os.makedirs(save_dir, exist_ok=True)
        csv_file = os.path.join(save_dir, f"{stock_code}_stock_data.csv")
        df_reset = df.reset_index()
        df_reset.to_csv(csv_file, encoding='utf-8-sig', index=False)
        print(f"ğŸ“ è‚¡ç¥¨æ•°æ®å·²ä¿å­˜: {csv_file}")
        return True
    return False


def get_stock_data(stock_code, data_dir):
    """
    è·å–è‚¡ç¥¨æ•°æ®ï¼Œå¦‚æœæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨åˆ™ä»APIè·å–çœŸå®æ•°æ®
    """
    csv_file_path = os.path.join(data_dir, f"{stock_code}_stock_data.csv")

    if os.path.exists(csv_file_path):
        print(f"ğŸ“ ä½¿ç”¨ç°æœ‰æ•°æ®æ–‡ä»¶: {csv_file_path}")
        return True, csv_file_path
    else:
        print(f"ğŸ“¡ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä»APIè·å–çœŸå®æ•°æ®...")
        df = get_stock_data_with_retry_all_history(stock_code)

        if df is not None and not df.empty:
            save_all_history_stock_data(df, stock_code, data_dir)
            return True, csv_file_path
        else:
            print(f"âŒ æ— æ³•è·å–è‚¡ç¥¨æ•°æ®")
            return False, None


def prepare_stock_data(csv_file_path, stock_code, history_years=1):
    """
    å‡†å¤‡è‚¡ç¥¨æ•°æ®ï¼Œè½¬æ¢ä¸ºKronosæ¨¡å‹éœ€è¦çš„æ ¼å¼
    """
    print(f"æ­£åœ¨åŠ è½½å’Œé¢„å¤„ç†è‚¡ç¥¨ {stock_code} æ•°æ®...")

    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(csv_file_path, encoding='utf-8-sig')

    # æ ‡å‡†åŒ–åˆ—å
    column_mapping = {
        'æ—¥æœŸ': 'timestamps',
        'å¼€ç›˜ä»·': 'open',
        'æœ€é«˜ä»·': 'high',
        'æœ€ä½ä»·': 'low',
        'æ”¶ç›˜ä»·': 'close',
        'æˆäº¤é‡': 'volume',
        'æˆäº¤é¢': 'amount',
        'å¼€ç›˜': 'open',
        'æ”¶ç›˜': 'close',
        'æœ€é«˜': 'high',
        'æœ€ä½': 'low'
    }

    actual_mapping = {k: v for k, v in column_mapping.items() if k in df.columns}
    df = df.rename(columns=actual_mapping)

    # ç¡®ä¿æ—¶é—´æˆ³åˆ—å­˜åœ¨å¹¶è½¬æ¢ä¸ºdatetimeæ ¼å¼
    if 'timestamps' not in df.columns:
        if df.index.name == 'æ—¥æœŸ':
            df = df.reset_index()
            df = df.rename(columns={'æ—¥æœŸ': 'timestamps'})

    df['timestamps'] = pd.to_datetime(df['timestamps'])
    df = df.sort_values('timestamps').reset_index(drop=True)

    # æ ¹æ®å†å²å¹´é™ç­›é€‰æ•°æ®
    if history_years > 0:
        cutoff_date = datetime.now() - timedelta(days=history_years * 365)
        original_count = len(df)
        df = df[df['timestamps'] >= cutoff_date]
        print(f"ğŸ“… ä½¿ç”¨æœ€è¿‘ {history_years} å¹´æ•°æ®: {len(df)} æ¡è®°å½• (ä» {original_count} æ¡ä¸­ç­›é€‰)")

    # æ•°æ®éªŒè¯
    print(f"ğŸ” æ•°æ®éªŒè¯ - æœ€è¿‘5ä¸ªäº¤æ˜“æ—¥æ”¶ç›˜ä»·:")
    recent_prices = df[['timestamps', 'close']].tail()
    for _, row in recent_prices.iterrows():
        print(f"  {row['timestamps'].strftime('%Y-%m-%d')}: {row['close']:.2f}å…ƒ")

    current_price = df['close'].iloc[-1]
    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
    print(f"æ—¶é—´èŒƒå›´: {df['timestamps'].min()} åˆ° {df['timestamps'].max()}")
    print(f"ä»·æ ¼èŒƒå›´: {df['close'].min():.2f} - {df['close'].max():.2f}")
    print(f"å½“å‰ä»·æ ¼: {current_price:.2f}å…ƒ")

    return df


def calculate_prediction_parameters(df, target_days=60):
    """
    æ ¹æ®ç›®æ ‡é¢„æµ‹å¤©æ•°è®¡ç®—åˆé€‚çš„å‚æ•°
    """
    # è®¡ç®—å¹³å‡äº¤æ˜“æ—¥æ•°é‡
    total_days = (df['timestamps'].max() - df['timestamps'].min()).days
    trading_days = len(df)
    trading_ratio = trading_days / total_days if total_days > 0 else 0.7

    # è®¡ç®—ç›®æ ‡é¢„æµ‹çš„äº¤æ˜“æ—¥æ•°é‡
    pred_trading_days = int(target_days * trading_ratio)

    # è®¾ç½®å›çœ‹æœŸæ•°
    max_lookback = int(len(df) * 0.7)
    lookback = min(pred_trading_days * 3, max_lookback, len(df) - pred_trading_days)
    pred_len = min(pred_trading_days, len(df) - lookback)

    # ç¡®ä¿å‚æ•°åœ¨åˆç†èŒƒå›´å†…
    lookback = max(100, min(lookback, 400))
    pred_len = max(20, min(pred_len, 120))

    print(f"ğŸ“Š å‚æ•°è®¡ç®—:")
    print(f"  ç›®æ ‡é¢„æµ‹å¤©æ•°: {target_days} å¤©ï¼ˆè‡ªç„¶æ—¥ï¼‰")
    print(f"  é¢„è®¡äº¤æ˜“æ—¥æ•°é‡: {pred_trading_days} å¤©")
    print(f"  å›çœ‹æœŸæ•° (lookback): {lookback}")
    print(f"  é¢„æµ‹æœŸæ•° (pred_len): {pred_len}")

    return lookback, pred_len


def generate_trading_dates_only(last_date, pred_len):
    """
    ğŸ¯ ä¿®å¤ç‰ˆï¼šåªç”Ÿæˆäº¤æ˜“æ—¥ï¼Œæ’é™¤å‘¨æœ«å’Œæ³•å®šèŠ‚å‡æ—¥
    """
    # 2025å¹´æ³•å®šèŠ‚å‡æ—¥å®‰æ’ï¼ˆä¿®æ­£ç‰ˆï¼‰
    holidays_2025 = [
        '2025-01-01',  # å…ƒæ—¦
        '2025-01-27', '2025-01-28', '2025-01-29', '2025-01-30', '2025-01-31', '2025-02-01', '2025-02-02',  # æ˜¥èŠ‚
        '2025-04-04', '2025-04-05', '2025-04-06',  # æ¸…æ˜
        '2025-05-01', '2025-05-02', '2025-05-03',  # åŠ³åŠ¨èŠ‚
        '2025-06-08', '2025-06-09', '2025-06-10',  # ç«¯åˆ
        '2025-10-01', '2025-10-02', '2025-10-03', '2025-10-04', '2025-10-05', '2025-10-06', '2025-10-07',  # å›½åº†èŠ‚
    ]

    holidays = [datetime.strptime(date, '%Y-%m-%d').date() for date in holidays_2025]

    trading_dates = []
    current_date = last_date + timedelta(days=1)

    while len(trading_dates) < pred_len:
        # æ’é™¤å‘¨æœ«å’ŒèŠ‚å‡æ—¥
        if current_date.weekday() < 5 and current_date.date() not in holidays:
            trading_dates.append(current_date)
        current_date += timedelta(days=1)

    print(f"ğŸ“… ç”Ÿæˆçš„çº¯äº¤æ˜“æ—¥: å…± {len(trading_dates)} å¤©")
    if trading_dates:
        print(f"   èµ·å§‹: {trading_dates[0].strftime('%Y-%m-%d')}")
        print(f"   ç»“æŸ: {trading_dates[-1].strftime('%Y-%m-%d')}")

    return trading_dates


def calculate_optimal_interval(min_val, max_val):
    """
    è®¡ç®—æœ€ä¼˜çš„Yè½´åˆ»åº¦é—´éš”
    """
    range_val = max_val - min_val
    if range_val <= 0:
        return 1.0

    if range_val < 1:
        interval = 0.1
    elif range_val < 5:
        interval = 0.5
    elif range_val < 10:
        interval = 1.0
    elif range_val < 20:
        interval = 2.0
    elif range_val < 50:
        interval = 5.0
    elif range_val < 100:
        interval = 10.0
    elif range_val < 200:
        interval = 20.0
    elif range_val < 500:
        interval = 50.0
    else:
        interval = 100.0

    return interval


# ==================== å¢å¼ºç‰ˆå¸‚åœºå› ç´ åˆ†æå™¨ ====================
class EnhancedMarketFactorAnalyzer:
    """å¢å¼ºç‰ˆå¸‚åœºå› ç´ åˆ†æå™¨ - æ•´åˆæ›´å¤šç»´åº¦çš„å¸‚åœºå› ç´ """

    def __init__(self):
        self.market_data = {}
        self.sector_data = {}
        self.macro_factors = {}
        self.policy_factors = {}

    def analyze_market_trend(self, index_codes=["000001", "399001"]):
        """
        åˆ†æå¤§ç›˜è¶‹åŠ¿ - å¤šæŒ‡æ•°ç»¼åˆåˆ†æ
        """
        try:
            print(f"ğŸ“Š ç»¼åˆåˆ†æå¤§ç›˜è¶‹åŠ¿...")

            market_analysis = {}

            for index_code in index_codes:
                index_name = "ä¸Šè¯æŒ‡æ•°" if index_code == "000001" else "æ·±è¯æˆæŒ‡"
                print(f"  åˆ†æ{index_name}({index_code})...")

                # è·å–æŒ‡æ•°æ•°æ®
                index_df = ak.stock_zh_index_hist(symbol=index_code, period="daily")

                if index_df is None or index_df.empty:
                    print(f"  âŒ æ— æ³•è·å–{index_name}æ•°æ®")
                    continue

                # é‡å‘½ååˆ—
                index_df = index_df.rename(columns={
                    'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close', 'å¼€ç›˜': 'open',
                    'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume'
                })
                index_df['date'] = pd.to_datetime(index_df['date'])
                index_df = index_df.sort_values('date').reset_index(drop=True)

                # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                index_df['ma5'] = index_df['close'].rolling(5).mean()
                index_df['ma20'] = index_df['close'].rolling(20).mean()
                index_df['ma60'] = index_df['close'].rolling(60).mean()
                index_df['vol_ma5'] = index_df['volume'].rolling(5).mean()

                # æŠ€æœ¯åˆ†æ
                current_data = index_df.iloc[-1]
                prev_data = index_df.iloc[-2]

                # å‡çº¿å¤šå¤´æ’åˆ—åˆ¤æ–­
                ma_condition = (current_data['ma5'] > current_data['ma20'] > current_data['ma60'])

                # ä»·æ ¼ç«™åœ¨20æ—¥å‡çº¿ä»¥ä¸Š
                price_above_ma20 = current_data['close'] > current_data['ma20']

                # æˆäº¤é‡é…åˆ
                volume_condition = current_data['volume'] > current_data['vol_ma5'] * 0.8

                # è¶‹åŠ¿å¼ºåº¦
                trend_strength = self._calculate_trend_strength(index_df)

                is_main_uptrend = ma_condition and price_above_ma20 and trend_strength > 0.6

                market_analysis[index_name] = {
                    'is_main_uptrend': is_main_uptrend,
                    'trend_strength': trend_strength,
                    'current_close': current_data['close'],
                    'price_change_pct': ((current_data['close'] - prev_data['close']) / prev_data['close']) * 100,
                    'market_status': 'ä¸»å‡æµª' if is_main_uptrend else 'éœ‡è¡è°ƒæ•´'
                }

            # ç»¼åˆåˆ¤æ–­
            if market_analysis:
                avg_trend_strength = np.mean([data['trend_strength'] for data in market_analysis.values()])
                uptrend_count = sum(1 for data in market_analysis.values() if data['is_main_uptrend'])
                overall_uptrend = uptrend_count >= len(market_analysis) * 0.5

                final_analysis = {
                    'overall_is_main_uptrend': overall_uptrend,
                    'overall_trend_strength': avg_trend_strength,
                    'detailed_analysis': market_analysis,
                    'market_status': 'ä¸»å‡æµª' if overall_uptrend else 'éœ‡è¡è°ƒæ•´'
                }

                print(f"âœ… å¤§ç›˜åˆ†æå®Œæˆ: {final_analysis['market_status']}, ç»¼åˆè¶‹åŠ¿å¼ºåº¦: {avg_trend_strength:.2f}")
                return final_analysis

            return self._get_default_market_analysis()

        except Exception as e:
            print(f"âŒ å¤§ç›˜åˆ†æé”™è¯¯: {e}")
            return self._get_default_market_analysis()

    def analyze_sector_resonance(self, stock_code):
        """
        åˆ†ææ¿å—å…±æŒ¯æ•ˆåº” - å¢å¼ºç‰ˆè¡Œä¸šåˆ†æ
        """
        try:
            print(f"ğŸ”„ åˆ†ææ¿å—å…±æŒ¯æ•ˆåº”...")

            # è·å–è‚¡ç¥¨æ‰€å±è¡Œä¸šå’Œæ¦‚å¿µ
            industry = "æœªçŸ¥"
            concepts = []

            try:
                stock_info = ak.stock_individual_info_em(symbol=stock_code)
                if not stock_info.empty and 'value' in stock_info.columns:
                    industry_row = stock_info[stock_info['item'] == 'è¡Œä¸š']
                    if not industry_row.empty:
                        industry = industry_row['value'].iloc[0]
            except:
                pass

            # çƒ­é—¨æ¿å—å’Œæ¦‚å¿µæ˜ å°„
            hot_sectors = {
                'æœºå™¨äºº': {'momentum': 0.85, 'limit_up_stocks': 18, 'active': True,
                           'description': 'äººå½¢æœºå™¨äººã€å·¥ä¸šè‡ªåŠ¨åŒ–'},
                'åŠå¯¼ä½“': {'momentum': 0.8, 'limit_up_stocks': 15, 'active': True, 'description': 'èŠ¯ç‰‡å›½äº§æ›¿ä»£'},
                'äººå·¥æ™ºèƒ½': {'momentum': 0.75, 'limit_up_stocks': 12, 'active': True, 'description': 'AIå¤§æ¨¡å‹ã€ç®—åŠ›'},
                'ä½ç©ºç»æµ': {'momentum': 0.7, 'limit_up_stocks': 10, 'active': True, 'description': 'æ— äººæœºã€eVTOL'},
                'æ–°èƒ½æº': {'momentum': 0.6, 'limit_up_stocks': 8, 'active': True, 'description': 'å…‰ä¼ã€å‚¨èƒ½'},
                'åŒ»è¯': {'momentum': 0.5, 'limit_up_stocks': 5, 'active': False, 'description': 'åˆ›æ–°è¯'}
            }

            # åˆ¤æ–­å½“å‰è‚¡ç¥¨æ‰€å±çƒ­é—¨æ¿å—
            matched_sectors = []
            for sector, data in hot_sectors.items():
                if (sector in industry or
                        (stock_code == '600580' and sector in ['æœºå™¨äºº', 'ä½ç©ºç»æµ']) or  # å§é¾™ç”µé©±ç‰¹æ®Šå¤„ç†
                        (stock_code == '300207' and sector in ['æ–°èƒ½æº'])):
                    matched_sectors.append({
                        'sector': sector,
                        'momentum': data['momentum'],
                        'limit_up_stocks': data['limit_up_stocks'],
                        'is_active': data['active'],
                        'description': data['description']
                    })

            # è®¡ç®—ç»¼åˆå…±æŒ¯åˆ†æ•°
            if matched_sectors:
                resonance_score = np.mean([sector['momentum'] for sector in matched_sectors])
                is_sector_hot = any(sector['is_active'] for sector in matched_sectors)
                main_sector = max(matched_sectors, key=lambda x: x['momentum'])
            else:
                resonance_score = 0.5
                is_sector_hot = False
                main_sector = {'sector': 'ä¼ ç»Ÿè¡Œä¸š', 'momentum': 0.5, 'description': 'æ— çƒ­é—¨æ¦‚å¿µ'}

            analysis = {
                'industry': industry,
                'matched_sectors': matched_sectors,
                'main_sector': main_sector,
                'is_sector_hot': is_sector_hot,
                'resonance_score': resonance_score,
                'sector_count': len(matched_sectors)
            }

            print(f"âœ… æ¿å—åˆ†æå®Œæˆ: {industry}, åŒ¹é…{len(matched_sectors)}ä¸ªçƒ­é—¨æ¿å—, å…±æŒ¯åˆ†æ•°: {resonance_score:.2f}")
            return analysis

        except Exception as e:
            print(f"âŒ æ¿å—åˆ†æé”™è¯¯: {e}")
            return self._get_default_sector_analysis()

    def analyze_macro_factors(self):
        """
        åˆ†æå®è§‚å› ç´  - ç»“åˆå›½å†…å¤–æ”¿ç­–
        """
        try:
            print(f"ğŸŒ åˆ†æå®è§‚å› ç´ ...")

            # ç¾å›½é™æ¯å‘¨æœŸåˆ†æ - åŸºäºæœ€æ–°ä¿¡æ¯
            us_rate_analysis = {
                'current_rate': 4.25,  # è”é‚¦åŸºé‡‘åˆ©ç‡ç›®æ ‡åŒºé—´4.00%-4.25%
                'trend': 'é™æ¯å‘¨æœŸ',
                'recent_cut': '2025å¹´9æœˆé™æ¯25ä¸ªåŸºç‚¹',
                'expected_cuts_2025': 2,  # å¸‚åœºé¢„æœŸ2025å¹´è¿˜æœ‰ä¸¤æ¬¡é™æ¯
                'expected_cuts_2026': 2,
                'impact_on_emerging_markets': 'positive',
                'usd_index_support': 95.0,  # ç¾å…ƒæŒ‡æ•°çŸ­æœŸæ”¯æ’‘ä½
                'analysis': 'ç¾è”å‚¨å¼€å¯å®½æ¾å‘¨æœŸï¼Œåˆ©å¥½å…¨çƒæµåŠ¨æ€§'
            }

            # å›½å†…æ”¿ç­–å› ç´  - åŸºäºæœ€æ–°æ”¿ç­–
            domestic_policy = {
                'monetary_policy': 'ç¨³å¥åæ¾',
                'fiscal_policy': 'ç§¯æè´¢æ”¿',
                'market_liquidity': 'åˆç†å……è£•',
                'industrial_policy': 'è®¾å¤‡æ›´æ–°ã€ä»¥æ—§æ¢æ–°',  # å¤§è§„æ¨¡è®¾å¤‡æ›´æ–°æ”¿ç­–
                'employment_policy': 'ç¨³å°±ä¸šæ”¿ç­–åŠ åŠ›',  # å›½åŠ¡é™¢ç¨³å°±ä¸šæ”¿ç­–
                'analysis': 'æ”¿ç­–ç»„åˆæ‹³å‘åŠ›ï¼Œç»æµç¨³ä¸­å‘å¥½'
            }

            # è¡Œä¸šæ”¿ç­–æ”¯æŒ
            industry_policy = {
                'robot_policy': 'æœºå™¨äººäº§ä¸šæ”¿ç­–æ”¯æŒ',
                'chip_policy': 'å›½äº§æ›¿ä»£åŠ é€Ÿæ¨è¿›',
                'AI_policy': 'äººå·¥æ™ºèƒ½å‘å±•è§„åˆ’',
                'low_altitude': 'ä½ç©ºç»æµå‘å±•è§„åˆ’'
            }

            macro_analysis = {
                'us_rate_cycle': us_rate_analysis,
                'domestic_policy': domestic_policy,
                'industry_policy': industry_policy,
                'global_liquidity_outlook': 'æ”¹å–„',
                'overall_macro_score': 0.75  # å®è§‚ç¯å¢ƒæ•´ä½“åç§¯æ
            }

            print(
                f"âœ… å®è§‚åˆ†æå®Œæˆ: ç¾å›½{us_rate_analysis['trend']}, å›½å†…æ”¿ç­–ç§¯æ, å®è§‚è¯„åˆ†: {macro_analysis['overall_macro_score']:.2f}")
            return macro_analysis

        except Exception as e:
            print(f"âŒ å®è§‚åˆ†æé”™è¯¯: {e}")
            return self._get_default_macro_analysis()

    def analyze_company_fundamentals(self, stock_code):
        """
        åˆ†æå…¬å¸åŸºæœ¬é¢ - é’ˆå¯¹ç‰¹å®šè‚¡ç¥¨
        """
        try:
            print(f"ğŸ¢ åˆ†æå…¬å¸åŸºæœ¬é¢...")

            # å§é¾™ç”µé©±ç‰¹æ®Šåˆ†æ
            if stock_code == '600580':
                fundamentals = {
                    'company_name': 'å§é¾™ç”µé©±',
                    'business_areas': ['å·¥ä¸šç”µæœº', 'æœºå™¨äººå…³é”®éƒ¨ä»¶', 'èˆªç©ºç”µæœº', 'æ–°èƒ½æºæ±½è½¦é©±åŠ¨'],
                    'recent_developments': [
                        'ä¸æ™ºå…ƒæœºå™¨äººå®ç°åŒå‘æŒè‚¡ï¼Œæ¨è¿›å…·èº«æ™ºèƒ½æœºå™¨äººæŠ€æœ¯ç ”å‘',
                        'æˆç«‹æµ™æ±Ÿé¾™é£ç”µé©±ï¼Œä¸“æ³¨èˆªç©ºç”µæœºä¸šåŠ¡',
                        'å‘å¸ƒAIå¤–éª¨éª¼æœºå™¨äººåŠçµå·§æ‰‹',
                        'å¸ƒå±€é«˜çˆ†å‘å…³èŠ‚æ¨¡ç»„ã€ä¼ºæœé©±åŠ¨å™¨ç­‰äººå½¢æœºå™¨äººå…³é”®éƒ¨ä»¶'
                    ],
                    'growth_drivers': [
                        'è®¾å¤‡æ›´æ–°æ”¿ç­–æ¨åŠ¨å·¥ä¸šç”µæœºéœ€æ±‚',
                        'æœºå™¨äººäº§ä¸šå¿«é€Ÿå‘å±•',
                        'ä½ç©ºç»æµæ”¿ç­–æ”¯æŒ',
                        'å‡ºæµ·æˆ˜ç•¥åŠ é€Ÿ'
                    ],
                    'risk_factors': [
                        'æœºå™¨äººä¸šåŠ¡è¥æ”¶å æ¯”ä»…2.71%ï¼Œå æ¯”è¾ƒä½',
                        'å·¥ä¸šéœ€æ±‚æ™¯æ°”åº¦æ³¢åŠ¨',
                        'åŸæ–™ä»·æ ¼æ³¢åŠ¨é£é™©'
                    ],
                    'investment_rating': 'ç§¯æå…³æ³¨',
                    'fundamental_score': 0.7
                }
            else:
                # å…¶ä»–è‚¡ç¥¨çš„åŸºç¡€åˆ†æ
                fundamentals = {
                    'company_name': 'æœªçŸ¥',
                    'business_areas': [],
                    'recent_developments': [],
                    'growth_drivers': [],
                    'risk_factors': [],
                    'investment_rating': 'ä¸­æ€§',
                    'fundamental_score': 0.5
                }

            print(f"âœ… åŸºæœ¬é¢åˆ†æå®Œæˆ: {fundamentals['company_name']}, è¯„åˆ†: {fundamentals['fundamental_score']:.2f}")
            return fundamentals

        except Exception as e:
            print(f"âŒ åŸºæœ¬é¢åˆ†æé”™è¯¯: {e}")
            return self._get_default_fundamental_analysis()

    def _calculate_trend_strength(self, df):
        """è®¡ç®—è¶‹åŠ¿å¼ºåº¦"""
        if len(df) < 20:
            return 0.5

        ma_slope = (df['ma5'].iloc[-1] - df['ma5'].iloc[-20]) / df['ma5'].iloc[-20]
        price_slope = (df['close'].iloc[-1] - df['close'].iloc[-20]) / df['close'].iloc[-20]

        volume_trend = df['volume'].iloc[-5:].mean() / df['volume'].iloc[-10:-5].mean()

        strength = (ma_slope * 0.4 + price_slope * 0.4 + min(volume_trend - 1, 0.2) * 0.2)
        return max(0, min(1, strength * 10))

    def _get_default_market_analysis(self):
        return {
            'overall_is_main_uptrend': False,
            'overall_trend_strength': 0.5,
            'market_status': 'æœªçŸ¥',
            'detailed_analysis': {}
        }

    def _get_default_sector_analysis(self):
        return {
            'industry': 'æœªçŸ¥',
            'matched_sectors': [],
            'main_sector': {'sector': 'æœªçŸ¥', 'momentum': 0.5, 'description': ''},
            'is_sector_hot': False,
            'resonance_score': 0.5,
            'sector_count': 0
        }

    def _get_default_macro_analysis(self):
        return {
            'us_rate_cycle': {'trend': 'æœªçŸ¥', 'expected_cuts_2025': 0},
            'domestic_policy': {'monetary_policy': 'ä¸­æ€§'},
            'overall_macro_score': 0.5
        }

    def _get_default_fundamental_analysis(self):
        return {
            'company_name': 'æœªçŸ¥',
            'business_areas': [],
            'recent_developments': [],
            'growth_drivers': [],
            'risk_factors': [],
            'investment_rating': 'ä¸­æ€§',
            'fundamental_score': 0.5
        }


# ==================== ä¼˜åŒ–çš„é¢„æµ‹å¹³æ»‘å‡½æ•° ====================
def smooth_prediction_results(prediction_df, historical_df, smooth_factor=0.3):
    """
    ğŸ¯ ä¼˜åŒ–é¢„æµ‹ç»“æœçš„å¹³æ»‘å¤„ç†ï¼Œé¿å…å‰§çƒˆæ³¢åŠ¨
    """
    print("ğŸ”„ åº”ç”¨é¢„æµ‹ç»“æœå¹³æ»‘å¤„ç†...")

    smoothed_df = prediction_df.copy()

    # è·å–å†å²æ•°æ®çš„è¶‹åŠ¿
    recent_trend = calculate_recent_trend(historical_df)

    # å¯¹ä»·æ ¼åºåˆ—è¿›è¡Œå¹³æ»‘
    price_columns = ['close', 'open', 'high', 'low']
    for col in price_columns:
        if col in smoothed_df.columns:
            original_values = smoothed_df[col].values

            # åº”ç”¨ç§»åŠ¨å¹³å‡å¹³æ»‘
            window_size = max(3, min(7, len(original_values) // 5))
            smoothed_values = pd.Series(original_values).rolling(
                window=window_size, center=True, min_periods=1
            ).mean()

            # ç»“åˆå†å²è¶‹åŠ¿è¿›è¡Œå¾®è°ƒ
            trend_adjusted = smoothed_values * (1 + recent_trend * smooth_factor)

            smoothed_df[col] = trend_adjusted.values

    # å¯¹æˆäº¤é‡è¿›è¡Œåˆç†è°ƒæ•´
    if 'volume' in smoothed_df.columns:
        hist_volume_mean = historical_df['volume'].tail(20).mean()
        current_volume = smoothed_df['volume'].values

        # ä¿æŒæˆäº¤é‡åœ¨åˆç†èŒƒå›´å†…
        volume_factor = 0.8 + 0.4 * np.random.random(len(current_volume))
        adjusted_volume = current_volume * volume_factor

        # ç¡®ä¿æˆäº¤é‡ä¸ä¼šå¼‚å¸¸æ³¢åŠ¨
        volume_std = historical_df['volume'].tail(50).std()
        volume_min = hist_volume_mean * 0.3
        volume_max = hist_volume_mean * 3.0

        smoothed_df['volume'] = np.clip(adjusted_volume, volume_min, volume_max)

    print("âœ… é¢„æµ‹ç»“æœå¹³æ»‘å®Œæˆ")
    return smoothed_df


def calculate_recent_trend(historical_df, lookback_days=20):
    """
    è®¡ç®—è¿‘æœŸä»·æ ¼è¶‹åŠ¿
    """
    if len(historical_df) < lookback_days:
        lookback_days = len(historical_df)

    recent_prices = historical_df['close'].tail(lookback_days).values
    if len(recent_prices) < 2:
        return 0

    # è®¡ç®—çº¿æ€§å›å½’æ–œç‡ä½œä¸ºè¶‹åŠ¿
    x = np.arange(len(recent_prices))
    slope = np.polyfit(x, recent_prices, 1)[0]

    # å½’ä¸€åŒ–ä¸ºè¶‹åŠ¿å¼ºåº¦ (-1 åˆ° 1)
    price_range = np.ptp(recent_prices)
    if price_range > 0:
        trend_strength = slope / price_range * len(recent_prices)
    else:
        trend_strength = 0

    return np.clip(trend_strength, -0.1, 0.1)  # é™åˆ¶è¶‹åŠ¿å¼ºåº¦


def apply_post_holiday_adjustment(prediction_df, future_dates, holiday_periods):
    """
    ğŸ¯ ä¿®å¤ç‰ˆï¼šåº”ç”¨èŠ‚åè°ƒæ•´ï¼Œé¿å…å›½åº†åå¼‚å¸¸ä¸‹è·Œ
    """
    print("ğŸ”„ åº”ç”¨èŠ‚åæ—¥å†æ•ˆåº”è°ƒæ•´...")

    adjusted_df = prediction_df.copy()

    for holiday in holiday_periods:
        holiday_start = pd.Timestamp(holiday['start'])
        holiday_end = pd.Timestamp(holiday['end'])
        adjustment_days = holiday['adjustment_days']
        effect_strength = holiday['effect_strength']

        # è®¡ç®—è°ƒæ•´æœŸç»“æŸæ—¥æœŸ
        adjustment_end = holiday_end + timedelta(days=adjustment_days)

        # æ‰¾åˆ°åœ¨èŠ‚åè°ƒæ•´æœŸå†…çš„æ—¥æœŸç´¢å¼•
        post_holiday_indices = []
        for i, date in enumerate(future_dates):
            if holiday_end <= date < adjustment_end:
                post_holiday_indices.append(i)

        # åº”ç”¨èŠ‚åæ•ˆåº”è°ƒæ•´
        if post_holiday_indices:
            for col in ['close', 'open', 'high', 'low']:
                if col in adjusted_df.columns:
                    for idx in post_holiday_indices:
                        adjusted_df.iloc[idx][col] = adjusted_df.iloc[idx][col] * (1 + effect_strength)

    print("âœ… èŠ‚åè°ƒæ•´å®Œæˆ")
    return adjusted_df


# ==================== ä»·æ ¼åˆç†æ€§æ£€æŸ¥å‡½æ•° ====================
def validate_prediction_results(historical_df, prediction_df, max_price_change=0.3):
    """
    ğŸ¯ éªŒè¯é¢„æµ‹ç»“æœçš„åˆç†æ€§ï¼Œé¿å…å¼‚å¸¸ä»·æ ¼æ³¢åŠ¨
    """
    print("ğŸ” éªŒè¯é¢„æµ‹ç»“æœåˆç†æ€§...")

    validated_df = prediction_df.copy()
    current_price = historical_df['close'].iloc[-1]

    # æ£€æŸ¥ä»·æ ¼åˆ—çš„åˆç†æ€§
    price_columns = ['close', 'open', 'high', 'low']

    for col in price_columns:
        if col in validated_df.columns:
            # è®¡ç®—æœ€å¤§å…è®¸çš„ä»·æ ¼å˜åŒ–èŒƒå›´
            max_allowed_change = current_price * max_price_change

            # æ£€æŸ¥æ¯ä¸ªé¢„æµ‹ä»·æ ¼
            for i in range(len(validated_df)):
                predicted_price = validated_df[col].iloc[i]

                # å¦‚æœé¢„æµ‹ä»·æ ¼è¶…å‡ºåˆç†èŒƒå›´ï¼Œè¿›è¡Œä¿®æ­£
                if abs(predicted_price - current_price) > max_allowed_change:
                    # åŸºäºå†å²æ³¢åŠ¨ç‡è¿›è¡Œä¿®æ­£
                    correction_factor = 0.8 + 0.4 * np.random.random()
                    corrected_price = current_price * (1 + (predicted_price / current_price - 1) * correction_factor)
                    validated_df.iloc[i][col] = corrected_price

                    print(f"âš ï¸  ä¿®æ­£å¼‚å¸¸{col}ä»·æ ¼: {predicted_price:.2f} -> {corrected_price:.2f}")

    print("âœ… é¢„æµ‹ç»“æœéªŒè¯å®Œæˆ")
    return validated_df


# ==================== GUIç‰ˆæœ¬é¢„æµ‹å‡½æ•° ====================
def run_comprehensive_prediction_gui(stock_code, stock_name, data_dir, pred_days, output_dir, history_years=1,
                                     progress_callback=None, result_callback=None):
    """
    GUIç‰ˆæœ¬çš„é¢„æµ‹å‡½æ•°
    """

    def update_progress(message):
        if progress_callback:
            progress_callback(message)
        print(message)

    def update_result(message):
        if result_callback:
            result_callback(message)
        print(message)

    try:
        # åˆå§‹åŒ–å¸‚åœºåˆ†æå™¨
        market_analyzer = EnhancedMarketFactorAnalyzer()

        update_progress(f"ğŸ¯ å¼€å§‹ {stock_name}({stock_code}) é¢„æµ‹æµç¨‹")
        update_progress("=" * 50)

        # 1. è·å–æ•°æ®
        update_progress("\næ­¥éª¤1: è·å–è‚¡ç¥¨æ•°æ®...")
        success, csv_file_path = get_stock_data(stock_code, data_dir)
        if not success:
            update_result("âŒ æ— æ³•è·å–è‚¡ç¥¨æ•°æ®ï¼Œé¢„æµ‹ç»ˆæ­¢")
            return False, "æ— æ³•è·å–è‚¡ç¥¨æ•°æ®"

        # 2. åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
        update_progress("\næ­¥éª¤2: åŠ è½½Kronosæ¨¡å‹å’Œåˆ†è¯å™¨...")
        try:
            tokenizer = KronosTokenizer.from_pretrained("NeoQuasar/Kronos-Tokenizer-base")
            model = Kronos.from_pretrained("NeoQuasar/Kronos-base")
            update_progress("âœ… æ¨¡å‹åŠ è½½å®Œæˆ - ä½¿ç”¨Kronos-baseæ¨¡å‹")
        except Exception as e:
            error_msg = f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}"
            update_result(error_msg)
            update_progress("âš ï¸ é¢„æµ‹åŠŸèƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æ¨¡å‹å®‰è£…")
            return False, error_msg

        # 3. å®ä¾‹åŒ–é¢„æµ‹å™¨
        update_progress("æ­¥éª¤3: åˆå§‹åŒ–é¢„æµ‹å™¨...")
        predictor = KronosPredictor(model, tokenizer, device="cuda:0", max_context=512)
        update_progress("âœ… é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")

        # 4. å‡†å¤‡æ•°æ®
        update_progress("æ­¥éª¤4: å‡†å¤‡è‚¡ç¥¨æ•°æ®...")
        df = prepare_stock_data(csv_file_path, stock_code, history_years)

        # 5. è®¡ç®—é¢„æµ‹å‚æ•°
        update_progress("æ­¥éª¤5: è®¡ç®—é¢„æµ‹å‚æ•°...")
        lookback, pred_len = calculate_prediction_parameters(df, target_days=pred_days)

        if pred_len <= 0:
            update_result("âŒ æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
            return False, "æ•°æ®é‡ä¸è¶³"

        update_progress(f"âœ… æœ€ç»ˆå‚æ•° - å›çœ‹æœŸ: {lookback}, é¢„æµ‹æœŸ: {pred_len}")

        # 6. å‡†å¤‡è¾“å…¥æ•°æ®
        update_progress("æ­¥éª¤6: å‡†å¤‡è¾“å…¥æ•°æ®...")
        x_df = df.loc[-lookback:, ['open', 'high', 'low', 'close', 'volume', 'amount']].reset_index(drop=True)
        x_timestamp = df.loc[-lookback:, 'timestamps'].reset_index(drop=True)

        # ç”Ÿæˆæœªæ¥æ—¥æœŸ - ğŸ¯ ä¿®å¤ï¼šåªç”Ÿæˆäº¤æ˜“æ—¥
        last_historical_date = df['timestamps'].iloc[-1]
        future_dates = generate_trading_dates_only(last_historical_date, pred_len)

        if len(future_dates) < pred_len:
            update_progress(f"âš ï¸ è­¦å‘Šï¼šåªç”Ÿæˆäº† {len(future_dates)} ä¸ªäº¤æ˜“æ—¥ï¼Œå°‘äºè¯·æ±‚çš„ {pred_len} å¤©")
            pred_len = len(future_dates)

        update_progress(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {x_df.shape}")
        update_progress(f"å†å²æ•°æ®æ—¶é—´èŒƒå›´: {x_timestamp.iloc[0]} åˆ° {x_timestamp.iloc[-1]}")
        if future_dates:
            update_progress(f"é¢„æµ‹æ—¶é—´èŒƒå›´: {future_dates[0]} åˆ° {future_dates[-1]}")

        # 7. æ‰§è¡ŒåŸºç¡€é¢„æµ‹
        update_progress("æ­¥éª¤7: æ‰§è¡ŒåŸºç¡€ä»·æ ¼é¢„æµ‹...")
        pred_df = predictor.predict(
            df=x_df,
            x_timestamp=x_timestamp,
            y_timestamp=pd.Series(future_dates),
            pred_len=pred_len,
            T=1.0,
            top_p=0.9,
            sample_count=1,
            verbose=True
        )

        update_progress("âœ… åŸºç¡€é¢„æµ‹å®Œæˆ")

        # ğŸ¯ æ–°å¢ï¼šå¯¹åŸºç¡€é¢„æµ‹è¿›è¡Œåˆç†æ€§æ£€æŸ¥
        update_progress("æ­¥éª¤7.2: éªŒè¯é¢„æµ‹ç»“æœåˆç†æ€§...")
        historical_df_for_validation = df.loc[-lookback:].reset_index(drop=True)
        validated_pred_df = validate_prediction_results(historical_df_for_validation, pred_df)

        # ğŸ¯ æ–°å¢ï¼šå¯¹åŸºç¡€é¢„æµ‹è¿›è¡Œå¹³æ»‘å¤„ç†
        update_progress("æ­¥éª¤7.5: å¯¹é¢„æµ‹ç»“æœè¿›è¡Œå¹³æ»‘ä¼˜åŒ–...")
        smoothed_pred_df = smooth_prediction_results(validated_pred_df, historical_df_for_validation)

        # ğŸ¯ ä¿®å¤ï¼šåº”ç”¨èŠ‚åè°ƒæ•´ï¼ˆç‰¹åˆ«æ˜¯å›½åº†èŠ‚åï¼‰
        holiday_periods = [
            {
                'start': '2025-10-01',
                'end': '2025-10-09',  # å›½åº†åç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ˆ10æœˆ9æ—¥å‘¨å››ï¼‰
                'adjustment_days': 5,
                'effect_strength': 0.03  # èŠ‚åé€šå¸¸æœ‰æ­£é¢æ•ˆåº”
            }
        ]

        adjusted_pred_df = apply_post_holiday_adjustment(smoothed_pred_df, future_dates, holiday_periods)

        # 8. ä½¿ç”¨å¤šç»´åº¦å¸‚åœºå› ç´ å¢å¼ºé¢„æµ‹
        update_progress("æ­¥éª¤8: åº”ç”¨å¤šç»´åº¦å¸‚åœºå› ç´ å¢å¼ºé¢„æµ‹...")
        enhanced_pred_df, enhancement_info = enhance_prediction_with_market_factors(
            df.loc[-lookback:].reset_index(drop=True),
            adjusted_pred_df,  # ä½¿ç”¨å¹³æ»‘è°ƒæ•´åçš„é¢„æµ‹ç»“æœ
            stock_code,
            market_analyzer
        )

        # å°†å¢å¼ºé¢„æµ‹ç»“æœæ·»åŠ åˆ°ä¿¡æ¯ä¸­
        enhancement_info['enhanced_prediction'] = enhanced_pred_df

        # 9. åˆ›å»ºç»¼åˆå¸‚åœºåˆ†ææŠ¥å‘Š
        update_progress("æ­¥éª¤9: åˆ›å»ºå¸‚åœºåˆ†ææŠ¥å‘Š...")
        market_report = create_comprehensive_market_report(enhancement_info, output_dir, stock_code)

        # 10. ç”Ÿæˆé¢„æµ‹å›¾è¡¨
        update_progress("æ­¥éª¤10: ç”Ÿæˆé¢„æµ‹å›¾è¡¨...")
        historical_df = df.loc[-lookback:].reset_index(drop=True)
        chart_path = plot_optimized_prediction_gui(
            historical_df, adjusted_pred_df, enhanced_pred_df, future_dates,
            stock_code, stock_name, output_dir, enhancement_info
        )

        # 11. ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š
        update_progress("æ­¥éª¤11: ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š...")
        if len(enhanced_pred_df) > 0:
            current_price = historical_df['close'].iloc[-1]
            base_predicted_price = adjusted_pred_df['close'].iloc[-1] if len(adjusted_pred_df) > 0 else current_price
            enhanced_predicted_price = enhanced_pred_df['close'].iloc[-1]

            base_change_pct = (base_predicted_price / current_price - 1) * 100
            enhanced_change_pct = (enhanced_predicted_price / current_price - 1) * 100

            # è¾“å‡ºé¢„æµ‹ç»“æœ
            update_result(f"\nğŸ“ˆ {stock_name}({stock_code}) é¢„æµ‹æŠ¥å‘Š")
            update_result("=" * 50)
            update_result(f"å½“å‰ä»·æ ¼: {current_price:.2f} å…ƒ")
            update_result(f"å¹³æ»‘é¢„æµ‹ä»·æ ¼: {base_predicted_price:.2f} å…ƒ ({base_change_pct:+.2f}%)")
            update_result(f"å¢å¼ºé¢„æµ‹ä»·æ ¼: {enhanced_predicted_price:.2f} å…ƒ ({enhanced_change_pct:+.2f}%)")
            update_result(f"å¸‚åœºå› ç´ è°ƒæ•´å› å­: {enhancement_info['adjustment_factor']:.4f}")
            update_result(f"å¤§ç›˜çŠ¶æ€: {enhancement_info['market_analysis']['market_status']}")
            update_result(f"æ¿å—å…±æŒ¯: {enhancement_info['sector_analysis']['main_sector']['sector']}")
            update_result(f"å®è§‚ç¯å¢ƒ: ç¾å›½{enhancement_info['macro_analysis']['us_rate_cycle']['trend']}")
            update_result(f"å…¬å¸è¯„çº§: {enhancement_info['fundamental_analysis']['investment_rating']}")

            # ä¿å­˜è¯¦ç»†é¢„æµ‹æ•°æ®
            prediction_details = pd.DataFrame({
                'æ—¥æœŸ': future_dates,
                'å¹³æ»‘é¢„æµ‹æ”¶ç›˜ä»·': adjusted_pred_df['close'].values if len(
                    adjusted_pred_df) > 0 else [current_price] * len(future_dates),
                'å¢å¼ºé¢„æµ‹æ”¶ç›˜ä»·': enhanced_pred_df['close'].values,
                'é¢„æµ‹æˆäº¤é‡': enhanced_pred_df['volume'].values
            })

            prediction_file = os.path.join(output_dir, f'{stock_code}_comprehensive_predictions.csv')
            prediction_details.to_csv(prediction_file, index=False, encoding='utf-8-sig')
            update_progress(f"ğŸ’¾ è¯¦ç»†é¢„æµ‹æ•°æ®å·²ä¿å­˜: {prediction_file}")

        update_progress(f"\nğŸ‰ {stock_name}({stock_code}) é¢„æµ‹å®Œæˆ!")
        update_progress(f"ğŸ“Š é¢„æµ‹å›¾è¡¨: {chart_path}")

        return True, "é¢„æµ‹å®Œæˆ"

    except Exception as e:
        error_msg = f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}"
        update_result(error_msg)
        import traceback
        traceback.print_exc()
        return False, error_msg


def enhance_prediction_with_market_factors(historical_df, prediction_df, stock_code, market_analyzer):
    """
    ä½¿ç”¨å¸‚åœºå› ç´ å¢å¼ºé¢„æµ‹ç»“æœ
    """
    print("\nğŸ¯ ä½¿ç”¨å¸‚åœºå› ç´ å¢å¼ºé¢„æµ‹...")

    # è·å–å„ç±»å¸‚åœºåˆ†æ
    market_analysis = market_analyzer.analyze_market_trend()
    sector_analysis = market_analyzer.analyze_sector_resonance(stock_code)
    macro_analysis = market_analyzer.analyze_macro_factors()
    fundamental_analysis = market_analyzer.analyze_company_fundamentals(stock_code)

    # è®¡ç®—ç»¼åˆè°ƒæ•´å› å­
    adjustment_factor = calculate_enhanced_adjustment_factor(
        market_analysis, sector_analysis, macro_analysis, fundamental_analysis
    )

    print(f"ğŸ“ˆ ç»¼åˆè°ƒæ•´å› å­: {adjustment_factor:.4f}")

    # åº”ç”¨è°ƒæ•´åˆ°é¢„æµ‹ç»“æœ
    enhanced_prediction = prediction_df.copy()

    # å¯¹ä»·æ ¼é¢„æµ‹è¿›è¡Œè°ƒæ•´
    price_columns = ['close', 'open', 'high', 'low']
    for col in price_columns:
        if col in enhanced_prediction.columns:
            enhanced_prediction[col] = enhanced_prediction[col] * adjustment_factor

    # å¯¹æˆäº¤é‡è¿›è¡Œè°ƒæ•´
    if 'volume' in enhanced_prediction.columns:
        volume_adjustment = 1 + (adjustment_factor - 1) * 0.3
        enhanced_prediction['volume'] = enhanced_prediction['volume'] * volume_adjustment

    return enhanced_prediction, {
        'market_analysis': market_analysis,
        'sector_analysis': sector_analysis,
        'macro_analysis': macro_analysis,
        'fundamental_analysis': fundamental_analysis,
        'adjustment_factor': adjustment_factor
    }


def calculate_enhanced_adjustment_factor(market_analysis, sector_analysis, macro_analysis, fundamental_analysis):
    """
    è®¡ç®—åŸºäºå¤šç»´åº¦å¸‚åœºå› ç´ çš„è°ƒæ•´å› å­
    """
    base_factor = 1.0

    # 1. å¤§ç›˜è¶‹åŠ¿å½±å“ (æƒé‡25%)
    if market_analysis['overall_is_main_uptrend']:
        trend_strength = market_analysis['overall_trend_strength']
        base_factor *= (1 + trend_strength * 0.08)
    else:
        trend_strength = market_analysis['overall_trend_strength']
        base_factor *= (1 + (trend_strength - 0.5) * 0.04)

    # 2. æ¿å—å…±æŒ¯å½±å“ (æƒé‡25%)
    resonance_score = sector_analysis['resonance_score']
    sector_count = sector_analysis['sector_count']

    if sector_analysis['is_sector_hot']:
        base_factor *= (1 + resonance_score * 0.06 + min(sector_count * 0.01, 0.03))
    else:
        base_factor *= (1 + (resonance_score - 0.5) * 0.02)

    # 3. å®è§‚å› ç´ å½±å“ (æƒé‡20%)
    macro_score = macro_analysis['overall_macro_score']
    base_factor *= (1 + (macro_score - 0.5) * 0.06)

    # 4. ç¾å›½é™æ¯å‘¨æœŸç‰¹æ®Šå½±å“ (æƒé‡10%)
    us_rate_trend = macro_analysis['us_rate_cycle']['trend']
    if us_rate_trend == 'é™æ¯å‘¨æœŸ':
        expected_cuts = macro_analysis['us_rate_cycle']['expected_cuts_2025']
        base_factor *= (1 + expected_cuts * 0.015)

    # 5. å…¬å¸åŸºæœ¬é¢å½±å“ (æƒé‡20%)
    fundamental_score = fundamental_analysis['fundamental_score']
    base_factor *= (1 + (fundamental_score - 0.5) * 0.08)

    # ğŸ¯ é™åˆ¶è°ƒæ•´å¹…åº¦åœ¨æ›´åˆç†èŒƒå›´å†… (0.9 ~ 1.1)ï¼Œé¿å…è¿‡åº¦è°ƒæ•´
    return max(0.9, min(1.1, base_factor))


def create_comprehensive_market_report(enhancement_info, output_dir, stock_code):
    """
    åˆ›å»ºç»¼åˆå¸‚åœºåˆ†ææŠ¥å‘Š
    """
    report = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'stock_code': stock_code,
        'market_analysis': enhancement_info['market_analysis'],
        'sector_analysis': enhancement_info['sector_analysis'],
        'macro_analysis': enhancement_info['macro_analysis'],
        'fundamental_analysis': enhancement_info['fundamental_analysis'],
        'adjustment_factor': enhancement_info['adjustment_factor']
    }

    # ä¿å­˜æŠ¥å‘Š
    report_file = os.path.join(output_dir, f'{stock_code}_comprehensive_analysis_report.json')
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“‹ ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    return report


def plot_optimized_prediction_gui(historical_df, base_pred_df, enhanced_pred_df, future_trading_dates,
                                  stock_code, stock_name, output_dir, enhancement_info=None):
    """
    ğŸ¯ ä¼˜åŒ–ç‰ˆï¼šæ¸…æ™°æ˜¾ç¤ºæ¯ä¸ªäº¤æ˜“æ—¥çš„é¢„æµ‹å›¾è¡¨
    """
    ensure_output_directory(output_dir)

    # è®¾ç½®é…è‰²
    colors = {
        'historical': '#1f77b4',
        'prediction': '#ff7f0e',
        'enhanced': '#2ca02c',
        'background': '#f8f9fa',
        'grid': '#e9ecef'
    }

    # åˆ›å»ºå›¾è¡¨
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle(f'{stock_name}({stock_code}) - ä¼˜åŒ–ç‰ˆäº¤æ˜“æ—¥é¢„æµ‹å›¾è¡¨', fontsize=16, fontweight='bold')

    # è®¾ç½®èƒŒæ™¯è‰²
    fig.patch.set_facecolor('white')
    for ax in [ax1, ax2, ax3, ax4]:
        ax.set_facecolor(colors['background'])

    # ğŸ¯ ä¼˜åŒ–1: ä½¿ç”¨å®é™…æ—¥æœŸä½œä¸ºxè½´ï¼Œä½†åªæ˜¾ç¤ºäº¤æ˜“æ—¥
    all_dates = list(historical_df['timestamps']) + future_trading_dates

    # 1. ä¸»ä»·æ ¼å›¾è¡¨
    current_price = historical_df['close'].iloc[-1]

    # ç»˜åˆ¶å†å²ä»·æ ¼
    ax1.plot(historical_df['timestamps'], historical_df['close'],
             color=colors['historical'], linewidth=2.5, label='å†å²ä»·æ ¼')

    # ç»˜åˆ¶é¢„æµ‹ä»·æ ¼
    if len(future_trading_dates) > 0:
        # ç»˜åˆ¶åŸºç¡€é¢„æµ‹
        ax1.plot(future_trading_dates, base_pred_df['close'],
                 color=colors['prediction'], linewidth=2, label='å¹³æ»‘é¢„æµ‹', linestyle='--')

        # ç»˜åˆ¶å¢å¼ºé¢„æµ‹
        ax1.plot(future_trading_dates, enhanced_pred_df['close'],
                 color=colors['enhanced'], linewidth=2.5, label='å¢å¼ºé¢„æµ‹')

        # ğŸ¯ ä¿®å¤ï¼šä½¿ç”¨æ›´å®‰å…¨çš„å…³é”®æ—¥æœŸæ ‡è®°
        mark_key_dates_safe(ax1, future_trading_dates, enhanced_pred_df)

    ax1.set_ylabel('æ”¶ç›˜ä»· (å…ƒ)', fontsize=12, fontweight='bold')
    ax1.legend(loc='upper left', fontsize=10)
    ax1.grid(True, color=colors['grid'], alpha=0.7)
    ax1.set_title(f'ä»·æ ¼èµ°åŠ¿é¢„æµ‹ - å½“å‰ä»·: {current_price:.2f}å…ƒ', fontweight='bold', fontsize=13)

    # ğŸ¯ ä¼˜åŒ–2: ä½¿ç”¨æ¯å‘¨æ ‡è®°ï¼Œé¿å…è¿‡äºå¯†é›†
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax1.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO, interval=2))  # æ¯ä¸¤å‘¨ä¸€ä¸ªæ ‡è®°
    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, fontsize=9)

    # 2. æˆäº¤é‡å›¾è¡¨
    ax2.bar(historical_df['timestamps'], historical_df['volume'],
            alpha=0.6, color=colors['historical'], label='å†å²æˆäº¤é‡')

    if len(future_trading_dates) > 0:
        ax2.bar(future_trading_dates, enhanced_pred_df['volume'],
                alpha=0.6, color=colors['enhanced'], label='é¢„æµ‹æˆäº¤é‡')

    ax2.set_ylabel('æˆäº¤é‡', fontsize=12, fontweight='bold')
    ax2.legend(loc='upper left', fontsize=10)
    ax2.grid(True, color=colors['grid'], alpha=0.7)
    ax2.set_title('æˆäº¤é‡é¢„æµ‹', fontweight='bold', fontsize=13)
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax2.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO, interval=2))
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, fontsize=9)

    # 3. ä»·æ ¼å˜åŒ–ç‡å›¾è¡¨
    ax3.plot(historical_df['timestamps'], historical_df['close'].pct_change() * 100,
             color=colors['historical'], linewidth=1.5, label='å†å²æ¶¨è·Œå¹…', alpha=0.7)

    if len(future_trading_dates) > 0:
        pred_returns = enhanced_pred_df['close'].pct_change() * 100
        ax3.plot(future_trading_dates, pred_returns,
                 color=colors['enhanced'], linewidth=2, label='é¢„æµ‹æ¶¨è·Œå¹…')

        # æ·»åŠ é›¶çº¿å‚è€ƒ
        ax3.axhline(y=0, color='red', linestyle='-', alpha=0.3, linewidth=1)

    ax3.set_ylabel('æ—¥æ¶¨è·Œå¹… (%)', fontsize=12, fontweight='bold')
    ax3.legend(loc='upper left', fontsize=10)
    ax3.grid(True, color=colors['grid'], alpha=0.7)
    ax3.set_title('ä»·æ ¼å˜åŒ–ç‡åˆ†æ', fontweight='bold', fontsize=13)
    ax3.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    ax3.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.MO, interval=2))
    plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, fontsize=9)

    # 4. å¸‚åœºå› ç´ åˆ†æ
    if enhancement_info:
        factors = ['å¤§ç›˜è¶‹åŠ¿', 'æ¿å—å…±æŒ¯', 'å®è§‚ç¯å¢ƒ', 'ç¾å›½é™æ¯', 'åŸºæœ¬é¢']
        scores = [
            enhancement_info['market_analysis']['overall_trend_strength'],
            enhancement_info['sector_analysis']['resonance_score'],
            enhancement_info['macro_analysis']['overall_macro_score'],
            0.7 if enhancement_info['macro_analysis']['us_rate_cycle']['trend'] == 'é™æ¯å‘¨æœŸ' else 0.3,
            enhancement_info['fundamental_analysis']['fundamental_score']
        ]

        colors_bars = [colors['historical'], colors['prediction'], colors['enhanced'], '#f39c12', '#9b59b6']

        bars = ax4.bar(factors, scores, color=colors_bars, alpha=0.8, edgecolor='black', linewidth=1)
        ax4.set_ylim(0, 1)
        ax4.set_ylabel('è¯„åˆ†', fontsize=12, fontweight='bold')
        ax4.set_title('å¸‚åœºå› ç´ è¯„åˆ†åˆ†æ', fontweight='bold', fontsize=13)
        ax4.grid(True, alpha=0.3, axis='y')

        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ˜¾ç¤ºå…·ä½“æ•°å€¼
        for i, (bar, score) in enumerate(zip(bars, scores)):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width() / 2., height + 0.02,
                     f'{score:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')

        # æ·»åŠ å¹³å‡çº¿
        avg_score = np.mean(scores)
        ax4.axhline(y=avg_score, color='red', linestyle='--', alpha=0.7,
                    label=f'å¹³å‡åˆ†: {avg_score:.2f}')
        ax4.legend(loc='upper right', fontsize=9)

    plt.tight_layout()

    # ä¿å­˜å›¾ç‰‡
    chart_filename = os.path.join(output_dir, f'{stock_code}_optimized_prediction.png')
    plt.savefig(chart_filename, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"ğŸ“Š ä¼˜åŒ–ç‰ˆé¢„æµ‹å›¾è¡¨å·²ä¿å­˜: {chart_filename}")
    return chart_filename


def mark_key_dates_safe(ax, future_dates, pred_df):
    """
    ğŸ¯ å®‰å…¨ç‰ˆï¼šæ ‡è®°å…³é”®æ—¥æœŸå’Œä»·æ ¼ç‚¹ï¼Œé¿å…ç±»å‹é”™è¯¯
    """
    if len(future_dates) == 0 or len(pred_df) == 0:
        return

    try:
        # é‡ç½®ç´¢å¼•ç¡®ä¿ä½¿ç”¨æ•´æ•°ç´¢å¼•
        pred_df_reset = pred_df.reset_index(drop=True)

        # è·å–æœ€é«˜ç‚¹å’Œæœ€ä½ç‚¹çš„æ•´æ•°ç´¢å¼•
        if hasattr(pred_df_reset['close'], 'idxmax'):
            max_idx = pred_df_reset['close'].idxmax()
            min_idx = pred_df_reset['close'].idxmin()
        else:
            # å¤‡ç”¨æ–¹æ³•
            max_idx = np.argmax(pred_df_reset['close'].values)
            min_idx = np.argmin(pred_df_reset['close'].values)

        # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
        max_idx = min(int(max_idx), len(future_dates) - 1)
        min_idx = min(int(min_idx), len(future_dates) - 1)

        # æ ‡è®°æœ€é«˜ç‚¹
        if 0 <= max_idx < len(future_dates):
            max_price = pred_df_reset['close'].iloc[max_idx]
            ax.plot(future_dates[max_idx], max_price,
                    'v', color='red', markersize=8, label=f'æœ€é«˜ç‚¹: {max_price:.2f}')

        # æ ‡è®°æœ€ä½ç‚¹
        if 0 <= min_idx < len(future_dates):
            min_price = pred_df_reset['close'].iloc[min_idx]
            ax.plot(future_dates[min_idx], min_price,
                    '^', color='green', markersize=8, label=f'æœ€ä½ç‚¹: {min_price:.2f}')

        # æ ‡è®°é¢„æµ‹ç»“æŸç‚¹
        if len(future_dates) > 0:
            final_price = pred_df_reset['close'].iloc[-1]
            ax.plot(future_dates[-1], final_price,
                    's', color='blue', markersize=6, label=f'æœ€ç»ˆé¢„æµ‹: {final_price:.2f}')

    except Exception as e:
        print(f"âš ï¸ æ ‡è®°å…³é”®æ—¥æœŸæ—¶å‡ºç°é”™è¯¯: {e}")
        # å¦‚æœå‡ºé”™ï¼Œè·³è¿‡æ ‡è®°ä½†ä¸å½±å“æ•´ä½“æµç¨‹


# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°ï¼šå¯åŠ¨GUIç•Œé¢"""
    root = tk.Tk()
    app = StockPredictorGUI(root)
    root.mainloop()


if __name__ == "__main__":
    main()
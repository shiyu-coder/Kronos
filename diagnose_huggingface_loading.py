#!/usr/bin/env python3
"""
è¯Šæ–­HuggingFaceæ¨¡å‹åŠ è½½å¤±è´¥çš„åŸå› 
åˆ†æPyTorchModelHubMixinçš„å·¥ä½œæœºåˆ¶
"""

import sys
import traceback
import requests
import json
from pathlib import Path
from huggingface_hub import PyTorchModelHubMixin, hf_hub_download
from huggingface_hub.utils import EntryNotFoundError

# æ·»åŠ modelæ¨¡å—åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / "model"))

try:
    from model import Kronos, KronosTokenizer, KronosPredictor
except ImportError:
    from kronos import KronosTokenizer, Kronos, KronosPredictor

def analyze_huggingface_model_structure():
    """åˆ†æHuggingFace Hubä¸Šçš„æ¨¡å‹ç»“æ„"""
    print("ğŸ” åˆ†æHuggingFaceæ¨¡å‹åŠ è½½å¤±è´¥åŸå› ")
    print("=" * 60)
    
    models_to_check = [
        "NeoQuasar/Kronos-Tokenizer-base",
        "NeoQuasar/Kronos-small"
    ]
    
    for model_name in models_to_check:
        print(f"\nğŸ“¦ æ£€æŸ¥æ¨¡å‹: {model_name}")
        print("-" * 40)
        
        # 1. æ£€æŸ¥æ¨¡å‹é…ç½®æ–‡ä»¶
        try:
            config_url = f"https://huggingface.co/{model_name}/raw/main/config.json"
            response = requests.get(config_url, timeout=10)
            if response.status_code == 200:
                config = response.json()
                print("âœ… æ‰¾åˆ°config.json:")
                for key, value in config.items():
                    print(f"   {key}: {value}")
            else:
                print(f"âŒ æ— æ³•è·å–config.json (çŠ¶æ€ç : {response.status_code})")
        except Exception as e:
            print(f"âŒ config.jsonè·å–å¤±è´¥: {e}")
        
        # 2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶åˆ—è¡¨
        try:
            files_url = f"https://huggingface.co/api/models/{model_name}"
            response = requests.get(files_url, timeout=10)
            if response.status_code == 200:
                model_info = response.json()
                if 'siblings' in model_info:
                    print("ğŸ“ æ¨¡å‹æ–‡ä»¶åˆ—è¡¨:")
                    for file_info in model_info['siblings']:
                        filename = file_info.get('rfilename', 'unknown')
                        size = file_info.get('size', 0)
                        print(f"   - {filename} ({size/1024/1024:.1f}MB)")
                else:
                    print("âŒ æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨")
            else:
                print(f"âŒ æ— æ³•è·å–æ¨¡å‹ä¿¡æ¯ (çŠ¶æ€ç : {response.status_code})")
        except Exception as e:
            print(f"âŒ æ¨¡å‹ä¿¡æ¯è·å–å¤±è´¥: {e}")
        
        # 3. æ£€æŸ¥PyTorchModelHubMixinæ‰€éœ€æ–‡ä»¶
        required_files = ['config.json', 'pytorch_model.bin', 'model.safetensors']
        for filename in required_files:
            try:
                file_url = f"https://huggingface.co/{model_name}/resolve/main/{filename}"
                response = requests.head(file_url, timeout=5)
                if response.status_code == 200:
                    print(f"âœ… {filename} å­˜åœ¨")
                else:
                    print(f"âŒ {filename} ä¸å­˜åœ¨ (çŠ¶æ€ç : {response.status_code})")
            except Exception as e:
                print(f"âš ï¸  {filename} æ£€æŸ¥å¤±è´¥: {e}")

def test_pytorch_model_hub_mixin():
    """æµ‹è¯•PyTorchModelHubMixinçš„å·¥ä½œåŸç†"""
    print("\nğŸ§ª æµ‹è¯•PyTorchModelHubMixinå·¥ä½œåŸç†")
    print("=" * 60)
    
    # æ£€æŸ¥PyTorchModelHubMixinçš„å®ç°
    print("ğŸ“‹ PyTorchModelHubMixinçš„from_pretrainedæ–¹æ³•å·¥ä½œæµç¨‹:")
    print("   1. ä¸‹è½½config.jsonæ–‡ä»¶")
    print("   2. ä½¿ç”¨config.jsonä¸­çš„å‚æ•°è°ƒç”¨cls(**config)")
    print("   3. ä¸‹è½½modelæƒé‡æ–‡ä»¶ (pytorch_model.bin æˆ– model.safetensors)")
    print("   4. åŠ è½½æƒé‡åˆ°æ¨¡å‹")
    
    # æ¨¡æ‹Ÿfrom_pretrainedçš„æ­¥éª¤
    model_name = "NeoQuasar/Kronos-Tokenizer-base"
    
    print(f"\nğŸ”¬ æ¨¡æ‹ŸåŠ è½½è¿‡ç¨‹: {model_name}")
    
    try:
        # æ­¥éª¤1: å°è¯•ä¸‹è½½config.json
        print("   æ­¥éª¤1: ä¸‹è½½config.json...")
        try:
            config_path = hf_hub_download(repo_id=model_name, filename="config.json")
            with open(config_path, 'r') as f:
                config = json.load(f)
            print("   âœ… config.jsonä¸‹è½½æˆåŠŸ:")
            for key, value in config.items():
                print(f"      {key}: {value}")
        except EntryNotFoundError:
            print("   âŒ config.jsonä¸å­˜åœ¨")
            config = None
        except Exception as e:
            print(f"   âŒ config.jsonä¸‹è½½å¤±è´¥: {e}")
            config = None
        
        # æ­¥éª¤2: å°è¯•ä½¿ç”¨é…ç½®åˆ›å»ºæ¨¡å‹
        if config:
            print("   æ­¥éª¤2: ä½¿ç”¨é…ç½®åˆ›å»ºæ¨¡å‹...")
            try:
                # æ£€æŸ¥å¿…éœ€å‚æ•°
                required_params = [
                    'd_in', 'd_model', 'n_heads', 'ff_dim', 'n_enc_layers', 'n_dec_layers',
                    'ffn_dropout_p', 'attn_dropout_p', 'resid_dropout_p', 's1_bits', 's2_bits',
                    'beta', 'gamma0', 'gamma', 'zeta', 'group_size'
                ]
                
                missing_params = [param for param in required_params if param not in config]
                if missing_params:
                    print(f"   âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_params}")
                else:
                    print("   âœ… æ‰€æœ‰å¿…éœ€å‚æ•°éƒ½å­˜åœ¨")
                    tokenizer = KronosTokenizer(**config)
                    print("   âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
                    
            except Exception as e:
                print(f"   âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        else:
            print("   æ­¥éª¤2: è·³è¿‡ï¼ˆæ— é…ç½®æ–‡ä»¶ï¼‰")
        
        # æ­¥éª¤3: æ£€æŸ¥æƒé‡æ–‡ä»¶
        print("   æ­¥éª¤3: æ£€æŸ¥æƒé‡æ–‡ä»¶...")
        weight_files = ['pytorch_model.bin', 'model.safetensors']
        for weight_file in weight_files:
            try:
                weight_path = hf_hub_download(repo_id=model_name, filename=weight_file)
                print(f"   âœ… {weight_file} å­˜åœ¨")
                break
            except EntryNotFoundError:
                print(f"   âŒ {weight_file} ä¸å­˜åœ¨")
            except Exception as e:
                print(f"   âš ï¸  {weight_file} æ£€æŸ¥å¤±è´¥: {e}")
                
    except Exception as e:
        print(f"   âŒ æ¨¡æ‹ŸåŠ è½½è¿‡ç¨‹å¤±è´¥: {e}")
        traceback.print_exc()

def analyze_model_class_structure():
    """åˆ†ææ¨¡å‹ç±»çš„ç»“æ„"""
    print("\nğŸ—ï¸  åˆ†ææ¨¡å‹ç±»ç»“æ„")
    print("=" * 60)
    
    # æ£€æŸ¥KronosTokenizerç±»
    print("ğŸ“‹ KronosTokenizerç±»åˆ†æ:")
    print(f"   - åŸºç±»: {KronosTokenizer.__bases__}")
    print(f"   - MRO: {KronosTokenizer.__mro__}")
    
    # æ£€æŸ¥__init__æ–¹æ³•
    import inspect
    sig = inspect.signature(KronosTokenizer.__init__)
    print("   - __init__å‚æ•°:")
    for param_name, param in sig.parameters.items():
        if param_name != 'self':
            print(f"     {param_name}: {param.annotation if param.annotation != param.empty else 'Any'}")
    
    # æ£€æŸ¥æ˜¯å¦æ­£ç¡®ç»§æ‰¿PyTorchModelHubMixin
    if hasattr(KronosTokenizer, 'from_pretrained'):
        print("   âœ… å…·æœ‰from_pretrainedæ–¹æ³•")
    else:
        print("   âŒ ç¼ºå°‘from_pretrainedæ–¹æ³•")

def provide_solutions():
    """æä¾›è§£å†³æ–¹æ¡ˆ"""
    print("\nğŸ’¡ é—®é¢˜åˆ†æä¸è§£å†³æ–¹æ¡ˆ")
    print("=" * 60)
    
    print("ğŸ” é—®é¢˜æ ¹æœ¬åŸå› :")
    print("   1. HuggingFace Hubä¸Šçš„æ¨¡å‹ç¼ºå°‘æ­£ç¡®çš„config.jsonæ–‡ä»¶")
    print("   2. config.jsonä¸­å¯èƒ½ç¼ºå°‘KronosTokenizer.__init__æ‰€éœ€çš„16ä¸ªå‚æ•°")
    print("   3. PyTorchModelHubMixin.from_pretrained()ä¾èµ–config.jsonæ¥åˆå§‹åŒ–æ¨¡å‹")
    
    print("\nğŸ› ï¸  è§£å†³æ–¹æ¡ˆ:")
    print("   æ–¹æ¡ˆ1: ä½¿ç”¨æˆ‘ä»¬çš„ä¿®å¤ç‰ˆè„šæœ¬ï¼ˆå·²å®ç°ï¼‰")
    print("     - è‡ªåŠ¨æ£€æµ‹åŠ è½½å¤±è´¥å¹¶ä½¿ç”¨é»˜è®¤é…ç½®")
    print("     - æä¾›å®Œæ•´çš„å‚æ•°å›é€€æœºåˆ¶")
    
    print("   æ–¹æ¡ˆ2: ä¿®å¤HuggingFace Hubä¸Šçš„æ¨¡å‹ï¼ˆæ¨¡å‹ä½œè€…éœ€è¦ï¼‰")
    print("     - ç¡®ä¿config.jsonåŒ…å«æ‰€æœ‰å¿…éœ€å‚æ•°")
    print("     - é‡æ–°ä¸Šä¼ æ¨¡å‹åˆ°HuggingFace Hub")
    
    print("   æ–¹æ¡ˆ3: æœ¬åœ°ä¿å­˜é…ç½®æ–‡ä»¶")
    print("     - åˆ›å»ºæœ¬åœ°config.jsonæ–‡ä»¶")
    print("     - ä½¿ç”¨æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹")
    
    print("\nğŸ“‹ æŠ€æœ¯ç»†èŠ‚:")
    print("   - PyTorchModelHubMixin.from_pretrained()å·¥ä½œæµç¨‹:")
    print("     1. ä¸‹è½½repoä¸­çš„config.json")
    print("     2. ä½¿ç”¨configè°ƒç”¨cls(**config)åˆå§‹åŒ–æ¨¡å‹")
    print("     3. ä¸‹è½½å¹¶åŠ è½½æƒé‡æ–‡ä»¶")
    print("   - å¤±è´¥ç‚¹ï¼šæ­¥éª¤2ï¼Œconfig.jsonç¼ºå°‘å¿…éœ€å‚æ•°")

def main():
    """ä¸»å‡½æ•°"""
    try:
        analyze_huggingface_model_structure()
        test_pytorch_model_hub_mixin()
        analyze_model_class_structure()
        provide_solutions()
        
        print("\nâœ… è¯Šæ–­å®Œæˆ!")
        print("ğŸ’¡ å»ºè®®: ä½¿ç”¨ä¿®å¤ç‰ˆè„šæœ¬ `run_a_share_prediction_fixed.py`")
        print("   å®ƒåŒ…å«å®Œæ•´çš„æ•…éšœå›é€€æœºåˆ¶ï¼Œå¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚")
        
    except Exception as e:
        print(f"\nâŒ è¯Šæ–­è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()